{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":107555,"databundleVersionId":13033998,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# FDS Challenge\n\nThis notebook will guide you through the first steps of the competition. Our goal here is to show you how to:\n\n1.  Load the `train.jsonl` and `test.jsonl` files from the competition data.\n2.  Create a very simple set of features from the data.\n3.  Train a basic model.\n4.  Generate a `submission.csv` file in the correct format.\n5.  Submit your results.\n\nLet's get started!","metadata":{"_uuid":"00713b04-49ef-4f25-9036-4177259b53e4","_cell_guid":"9cf7fcc7-f8d3-4f9a-9128-f94e5a717ff3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"# 1. Loading and Inspecting the Data","metadata":{"_uuid":"30695d23-3c14-4ded-ac54-0da74eab1161","_cell_guid":"b7c3e856-84d8-4080-97ee-7570902defbc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import json\nimport pandas as pd\nimport os\n\n# --- Define the path to our data ---\nCOMPETITION_NAME = 'fds-pokemon-battles-prediction-2025'\nDATA_PATH = os.path.join('../input', COMPETITION_NAME)\n\ntrain_file_path = os.path.join(DATA_PATH, 'train.jsonl')\ntest_file_path = os.path.join(DATA_PATH, 'test.jsonl')\ntrain_data = []\n\n# Read the file line by line\nprint(f\"Loading data from '{train_file_path}'...\")\ntry:\n    with open(train_file_path, 'r') as f:\n        for line in f:\n            # json.loads() parses one line (one JSON object) into a Python dictionary\n            train_data.append(json.loads(line))\n\n    print(f\"Successfully loaded {len(train_data)} battles.\")\n\n    # Let's inspect the first battle to see its structure\n    print(\"\\n--- Structure of the first train battle: ---\")\n    if train_data:\n        first_battle = train_data[0]\n        \n        # To keep the output clean, we can create a copy and truncate the timeline\n        battle_for_display = first_battle.copy()\n        battle_for_display['battle_timeline'] = battle_for_display.get('battle_timeline', [])[:2] # Show first 2 turns\n        \n        # Use json.dumps for pretty-printing the dictionary\n        print(json.dumps(battle_for_display, indent=4))\n        if len(first_battle.get('battle_timeline', [])) > 3:\n            print(\"    ...\")\n            print(\"    (battle_timeline has been truncated for display)\")\n\n\nexcept FileNotFoundError:\n    print(f\"ERROR: Could not find the training file at '{train_file_path}'.\")\n    print(\"Please make sure you have added the competition data to this notebook.\")","metadata":{"_uuid":"a0e3bcf2-ab61-499f-b5e6-c98aa1b68d6e","_cell_guid":"4151dbde-ac63-44b6-bc6a-dec9e4887644","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T21:03:43.38286Z","iopub.execute_input":"2025-11-14T21:03:43.383089Z","iopub.status.idle":"2025-11-14T21:03:50.5443Z","shell.execute_reply.started":"2025-11-14T21:03:43.38307Z","shell.execute_reply":"2025-11-14T21:03:50.543535Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Features Engineering","metadata":{"_uuid":"3a8ee9c9-3a1f-441a-9c71-6bd1445de82f","_cell_guid":"0e496703-c5aa-4a03-8262-f8f9c1d2f386","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# =========================\n# CELLA 2 — Feature Engineering \n# =========================\n\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport pandas as pd\nimport json\nfrom sklearn.preprocessing import RobustScaler\nfrom typing import List, Dict, Any, Tuple\nfrom collections import Counter, defaultdict\n\n# ---------------------------------------------\n# Base stat keys used throughout the feature extraction\n# ---------------------------------------------\nBASE_STAT_KEYS = [\"base_hp\",\"base_atk\",\"base_def\",\"base_spa\",\"base_spd\",\"base_spe\"]\n\n# ---------------------------------------------\n# Static team composition and stats\n# ---------------------------------------------\ndef unique_types(team: List[Dict[str, Any]]) -> int:\n    collected=[]\n    for p in team or []:\n        ts=p.get(\"types\") or []\n        if isinstance(ts,str): ts=[ts]\n        collected.extend([t for t in ts if t])\n    return len(set(collected))\n\ndef sum_stats_of_team(team: List[Dict[str, Any]]) -> float:\n    total=0.0\n    for p in team or []:\n        for k in BASE_STAT_KEYS:\n            v=p.get(k)\n            if isinstance(v,(int,float)):\n                total+=float(v)\n    return total\n\ndef avg_stats_of_team(team: List[Dict[str, Any]]) -> float:\n    if not team:\n        return 0.0\n    per=[]\n    for p in team:\n        vals=[p.get(k) for k in BASE_STAT_KEYS if isinstance(p.get(k),(int,float))]\n        if vals:\n            per.append(sum(vals)/len(vals))\n    return float(sum(per)/len(per)) if per else 0.0\n\ndef sum_and_avg_of_single(poke: dict) -> Tuple[float, float]:\n    vals = [poke.get(k) for k in BASE_STAT_KEYS if isinstance(poke.get(k), (int, float))]\n    if not vals:\n        return 0.0, 0.0\n    total = float(sum(vals))\n    return total, total / len(vals)\n\ndef team_stat_variance(team: List[Dict[str,Any]]) -> float:\n    if not team:\n        return 0.0\n    per=[]\n    for p in team:\n        vals=[p.get(k) for k in BASE_STAT_KEYS if isinstance(p.get(k),(int,float))]\n        if vals:\n            per.append(sum(vals)/len(vals))\n    if len(per)<2:\n        return 0.0\n    return float(pd.Series(per).var())\n\ndef _team_speed_stats(team):\n    \"\"\"Return mean and max base speed over a team.\"\"\"\n    sp = [p.get(\"base_spe\", 0.0) for p in team or [] if isinstance(p.get(\"base_spe\", None), (int, float))]\n    if not sp:\n        return 0.0, 0.0\n    return float(np.mean(sp)), float(np.max(sp))\n\n# ---------------------------------------------\n# General numeric helpers\n# ---------------------------------------------\ndef _safe_mean(arr): \n    return float(np.mean(arr)) if arr else 0.0\n\ndef _safe_ratio(a,b,cap=10.0):\n    r=a/(b+1e-6)\n    if r < 0: r = 0.0\n    if r > cap: r = cap\n    if not np.isfinite(r): r = 0.0\n    return float(r)\n\n# ---------------------------------------------\n# Timeline-based HP feature extraction\n# ---------------------------------------------\ndef get_timeline(r: Dict[str,Any], max_turns: int = 30):\n    tl = r.get(\"battle_timeline\",[]) or []\n    return tl[:max_turns] if isinstance(tl,list) else []\n\ndef _extract_hp_series(tl):\n    p1=[]; p2=[]\n    for t in tl:\n        if not isinstance(t,dict): \n            continue\n        s1=t.get(\"p1_pokemon_state\") or {}\n        s2=t.get(\"p2_pokemon_state\") or {}\n        v1=s1.get(\"hp_pct\"); v2=s2.get(\"hp_pct\")\n        if isinstance(v1,(int,float)) and isinstance(v2,(int,float)):\n            p1.append(float(v1)); p2.append(float(v2))\n    return p1,p2\n\ndef _mean_last_std_min(arr):\n    if not arr:\n        return 0.0,0.0,0.0,0.0\n    x=np.array(arr,dtype=float)\n    return float(x.mean()), float(x[-1]), float(x.std(ddof=0)), float(x.min())\n\ndef _window(arr,n): return arr[:n] if arr else []\ndef _frac_positive(arr): return float((np.array(arr)>0).mean()) if arr else 0.0\ndef _slope(arr):\n    if len(arr)<2: return 0.0\n    x=np.arange(len(arr))\n    m,_=np.polyfit(x,np.array(arr),1)\n    return float(m)\ndef _auc_pct(arr): return float(np.sum(arr)/(100.0*len(arr))) if arr else 0.0\ndef _status_count(tl,who):\n    cnt=0\n    k=f\"{who}_pokemon_state\"\n    for t in tl:\n        if not isinstance(t,dict): continue\n        st=(t.get(k) or {}).get(\"status\",None)\n        if st not in (None,\"\",\"none\",\"NONE\"):\n            cnt+=1\n    return float(cnt)\ndef _ko_count(arr): return float(sum(1 for v in arr if v==0))\n\n# ---------------------------------------------\n# Move-related statistics from timeline\n# ---------------------------------------------\ndef _move_stats_for_side(tl, who, window=None):\n    key=f\"{who}_move_details\"\n    seq = tl if window is None else tl[:window]\n    pw, ac, pr = [], [], []\n    for t in seq:\n        md=t.get(key) or {}\n        bp=md.get(\"base_power\"); acc=md.get(\"accuracy\"); pri=md.get(\"priority\")\n        if isinstance(bp,(int,float)): pw.append(float(bp))\n        if isinstance(acc,(int,float)): ac.append(float(acc))\n        if isinstance(pri,(int,float)): pr.append(float(pri))\n    suf=\"\" if window is None else f\"_{window}\"\n    return {\n        f\"mv_{who}_power_mean{suf}\": _safe_mean(pw),\n        f\"mv_{who}_acc_mean{suf}\":   _safe_mean(ac),\n        f\"mv_{who}_priority_mean{suf}\": _safe_mean(pr),\n    }\n# ---------------------------------------------\n# Type effectiveness helpers (uppercase canonical)\n# ---------------------------------------------\n_TYPE_CHART = {\n    \"NORMAL\":   {\"ROCK\":0.5, \"GHOST\":0.0, \"STEEL\":0.5},\n    \"FIRE\":     {\"FIRE\":0.5, \"WATER\":0.5, \"GRASS\":2.0, \"ICE\":2.0, \"BUG\":2.0, \"ROCK\":0.5, \"DRAGON\":0.5, \"STEEL\":2.0},\n    \"WATER\":    {\"FIRE\":2.0, \"WATER\":0.5, \"GRASS\":0.5, \"GROUND\":2.0, \"ROCK\":2.0, \"DRAGON\":0.5},\n    \"ELECTRIC\": {\"WATER\":2.0, \"ELECTRIC\":0.5, \"GRASS\":0.5, \"GROUND\":0.0, \"FLYING\":2.0, \"DRAGON\":0.5},\n    \"GRASS\":    {\"FIRE\":0.5, \"WATER\":2.0, \"GRASS\":0.5, \"POISON\":0.5, \"GROUND\":2.0, \"FLYING\":0.5, \"BUG\":0.5, \"ROCK\":2.0, \"DRAGON\":0.5, \"STEEL\":0.5},\n    \"ICE\":      {\"FIRE\":0.5, \"WATER\":0.5, \"GRASS\":2.0, \"GROUND\":2.0, \"FLYING\":2.0, \"DRAGON\":2.0, \"STEEL\":0.5},\n    \"FIGHTING\": {\"NORMAL\":2.0, \"ICE\":2.0, \"POISON\":0.5, \"FLYING\":0.5, \"PSYCHIC\":0.5, \"BUG\":0.5, \"ROCK\":2.0, \"GHOST\":0.0, \"DARK\":2.0, \"STEEL\":2.0, \"FAIRY\":0.5},\n    \"POISON\":   {\"GRASS\":2.0, \"POISON\":0.5, \"GROUND\":0.5, \"ROCK\":0.5, \"GHOST\":0.5, \"STEEL\":0.0, \"FAIRY\":2.0},\n    \"GROUND\":   {\"FIRE\":2.0, \"ELECTRIC\":2.0, \"GRASS\":0.5, \"POISON\":2.0, \"FLYING\":0.0, \"BUG\":0.5, \"ROCK\":2.0, \"STEEL\":2.0},\n    \"FLYING\":   {\"ELECTRIC\":0.5, \"GRASS\":2.0, \"FIGHTING\":2.0, \"BUG\":2.0, \"ROCK\":0.5, \"STEEL\":0.5},\n    \"PSYCHIC\":  {\"FIGHTING\":2.0, \"POISON\":2.0, \"PSYCHIC\":0.5, \"DARK\":0.0, \"STEEL\":0.5},\n    \"BUG\":      {\"FIRE\":0.5, \"GRASS\":2.0, \"FIGHTING\":0.5, \"POISON\":0.5, \"FLYING\":0.5, \"PSYCHIC\":2.0, \"GHOST\":0.5, \"DARK\":2.0, \"STEEL\":0.5, \"FAIRY\":0.5},\n    \"ROCK\":     {\"FIRE\":2.0, \"ICE\":2.0, \"FIGHTING\":0.5, \"GROUND\":0.5, \"FLYING\":2.0, \"BUG\":2.0, \"STEEL\":0.5},\n    \"GHOST\":    {\"NORMAL\":0.0, \"PSYCHIC\":2.0, \"GHOST\":2.0, \"DARK\":0.5},\n    \"DRAGON\":   {\"DRAGON\":2.0, \"STEEL\":0.5, \"FAIRY\":0.0},\n    \"DARK\":     {\"FIGHTING\":0.5, \"PSYCHIC\":2.0, \"GHOST\":2.0, \"DARK\":0.5, \"FAIRY\":0.5},\n    \"STEEL\":    {\"FIRE\":0.5, \"WATER\":0.5, \"ELECTRIC\":0.5, \"ICE\":2.0, \"ROCK\":2.0, \"FAIRY\":2.0, \"STEEL\":0.5},\n    \"FAIRY\":    {\"FIRE\":0.5, \"FIGHTING\":2.0, \"POISON\":0.5, \"DRAGON\":2.0, \"DARK\":2.0, \"STEEL\":0.5},\n}\n\ndef _type_multiplier(move_type: str, target_types: List[str] | set) -> float:\n    \"\"\"Effectiveness multiplier for move_type against mono/dual target types.\"\"\"\n    if not move_type:\n        return 1.0\n    mt = move_type.strip().upper()\n    mult = 1.0\n    for tt in target_types or []:\n        tt_up = str(tt).strip().upper()\n        mult *= _TYPE_CHART.get(mt, {}).get(tt_up, 1.0)\n    return float(mult) if np.isfinite(mult) else 1.0\n\ndef _avg_type_eff_p1_vs_p2lead(tl: list[dict], p2_lead_types: List[str] | set, window: int | None = None) -> float:\n    \"\"\"Mean effectiveness of P1 used moves vs P2 lead types over full/early window.\"\"\"\n    seq = tl if window is None else tl[:window]\n    vals = []\n    for t in seq:\n        md = t.get(\"p1_move_details\") or {}\n        mv_t = md.get(\"type\")\n        if isinstance(mv_t, str) and p2_lead_types:\n            vals.append(_type_multiplier(mv_t, p2_lead_types))\n    return float(np.mean(vals)) if vals else 1.0  # neutral if unknown\n\n# ---------------------------------------------\n# STAB features (Same-Type Attack Bonus)\n# ---------------------------------------------\ndef _name_to_types_map_p1(record: Dict[str, Any]) -> Dict[str, set]:\n    mp = {}\n    for p in record.get(\"p1_team_details\", []) or []:\n        nm = (p.get(\"name\") or \"\").strip().lower()\n        ts = p.get(\"types\") or []\n        if isinstance(ts, str):\n            ts = [ts]\n        ts_norm = {str(t).strip().upper() for t in ts if t and str(t).strip().upper() != \"NOTYPE\"}\n        if nm:\n            mp[nm] = ts_norm\n    return mp\n\ndef _active_name_and_move_type(turn: Dict[str, Any], who: str) -> tuple[str, str]:\n    state = turn.get(f\"{who}_pokemon_state\") or {}\n    md    = turn.get(f\"{who}_move_details\") or {}\n    nm = (state.get(\"name\") or \"\").strip().lower()\n    mv_t = (md.get(\"type\") or \"\").strip().upper()\n    return nm, mv_t\n\ndef _stab_features(record: Dict[str, Any], max_turns: int = 30) -> Dict[str, float]:\n    tl = get_timeline(record, max_turns=max_turns)\n\n    # type maps of P1 (name -> set(types))\n    p1_types_map = _name_to_types_map_p1(record)\n\n    # ratio & diff - helpers\n    def _accumulate(seq):\n        p1_total = p1_stab = 0\n        p2_total = p2_stab = 0  \n\n        for t in seq:\n            # P1\n            nm1, mv1_type = _active_name_and_move_type(t, \"p1\")\n            if mv1_type:\n                p1_total += 1\n                types1 = p1_types_map.get(nm1, set())\n                is_stab = (mv1_type in types1) if types1 else False\n                if is_stab:\n                    p1_stab += 1\n\n        p1_ratio = (p1_stab / p1_total) if p1_total > 0 else 0.0\n        p2_ratio = 0.0\n\n        return {\n            \"stab_stab_ratio_diff\": float(p1_ratio - p2_ratio),\n            \"stab_stab_ratio_ratio\": _safe_ratio(p1_ratio, p2_ratio if p2_ratio > 0 else 1e-6, cap=10.0),\n        }\n\n    full = _accumulate(tl)\n    w5   = _accumulate(tl[:5])\n\n    return {\n        \"stab_stab_ratio_diff_full\":  float(full[\"stab_stab_ratio_diff\"]),\n        \"stab_stab_ratio_ratio_full\": float(full[\"stab_stab_ratio_ratio\"]),\n        \"stab_stab_ratio_diff_w5\":    float(w5[\"stab_stab_ratio_diff\"]),\n        \"stab_stab_ratio_ratio_w5\":   float(w5[\"stab_stab_ratio_ratio\"]),\n    }\n\n# ---------------------------------------------\n# Early momentum (first 3 turns)\n# ---------------------------------------------\ndef _first_ko_flag(hp_series: list[float]) -> int:\n    for v in hp_series:\n        if isinstance(v, (int, float)) and float(v) == 0.0:\n            return 1\n    return 0\n\ndef _first_status_advantage(tl: list[dict], first_n: int = 3) -> float:\n    p1 = p2 = 0\n    for t in tl[:first_n]:\n        s1 = (t.get(\"p1_pokemon_state\") or {}).get(\"status\", None)\n        s2 = (t.get(\"p2_pokemon_state\") or {}).get(\"status\", None)\n        if s1 not in (None, \"\", \"none\", \"NONE\"): p1 += 1\n        if s2 not in (None, \"\", \"none\", \"NONE\"): p2 += 1\n    return float(p1 - p2)\n\ndef _early_momentum_features(record: Dict[str, Any], first_n: int = 3) -> Dict[str, float]:\n    tl = get_timeline(record, max_turns=30)\n    p1, p2 = _extract_hp_series(tl)\n    p1w, p2w = _window(p1, first_n), _window(p2, first_n)\n\n    diffw = [a - b for a, b in zip(p1w, p2w)] if p1w and p2w and len(p1w) == len(p2w) else []\n    mean_diff_first = float(np.mean(diffw)) if diffw else 0.0\n\n    p1_first_ko = _first_ko_flag(p2w)\n    p2_first_ko = _first_ko_flag(p1w)\n    first_ko_score = float(p1_first_ko - p2_first_ko)\n\n    status_adv = _first_status_advantage(tl, first_n=first_n)\n\n    return {\n        f\"early_hp_diff_mean_{first_n}\": mean_diff_first,\n        f\"early_first_ko_score_{first_n}\": first_ko_score,\n        f\"early_status_advantage_{first_n}\": status_adv,\n    }\n\n# ---------------------------------------------\n# Priority counts and advantage (full / 5 / 10)\n# ---------------------------------------------\ndef _priority_counts(record: Dict[str, Any], max_turns: int = 30, window: int | None = None) -> Dict[str, float]:\n    tl = get_timeline(record, max_turns=max_turns)\n    turns = tl if window is None else tl[:window]\n\n    p1_count = 0.0\n    p2_count = 0.0\n    for t in turns:\n        md1 = t.get(\"p1_move_details\") or {}\n        md2 = t.get(\"p2_move_details\") or {}\n        pri1 = md1.get(\"priority\")\n        pri2 = md2.get(\"priority\")\n        if isinstance(pri1, (int, float)) and float(pri1) > 0: p1_count += 1.0\n        if isinstance(pri2, (int, float)) and float(pri2) > 0: p2_count += 1.0\n\n    suf = \"\" if window is None else f\"_{window}\"\n    return {\n        f\"mv_p1_priority_count{suf}\": p1_count,\n        f\"mv_p2_priority_count{suf}\": p2_count,\n        f\"mv_priority_count_diff{suf}\": p1_count - p2_count,\n    }\n\ndef _priority_feature_block(record: Dict[str, Any]) -> Dict[str, float]:\n    f = {}\n    f.update(_priority_counts(record, max_turns=30, window=None))\n    f.update(_priority_counts(record, max_turns=30, window=5))\n    return f\n\n# ---------------------------------------------\n# Extra strong engineered features (top-5, safe, no NaN)\n# ---------------------------------------------\ndef extra_strong_features(record, tl, p1, p2, t1, lead):\n    \"\"\"\n    Extra high-signal features built on top of existing blocks.\n    Assumes:\n      - tl  : battle_timeline (<=30 turns)\n      - p1  : HP series for player 1\n      - p2  : HP series for player 2\n      - t1  : p1_team_details (list of dict)\n      - lead: p2_lead_details (dict)\n    Returns: dict of 5 new numeric features (float).\n    \"\"\"\n    f = {}\n\n    # --- Helper: safe list ops ---\n    def _safe_mean(arr):\n        return float(np.mean(arr)) if arr else 0.0\n\n    # ---------------------------------\n    # 1) Lead type coverage score\n    #    \"How many team attacking types hit the lead super effectively?\"\n    # ---------------------------------\n    # Collect attacking types from P1 moves (first 10 turns) and team composition\n    atk_types = set()\n    for t in tl[:10]:\n        if not isinstance(t, dict):\n            continue\n        md = t.get(\"p1_move_details\") or {}\n        mt = md.get(\"type\")\n        if isinstance(mt, str) and mt.strip():\n            atk_types.add(mt.strip().upper())\n\n    for p in t1 or []:\n        ts = p.get(\"types\") or []\n        if isinstance(ts, str):\n            ts = [ts]\n        for tt in ts:\n            if tt:\n                atk_types.add(str(tt).strip().upper())\n\n    lead_types = lead.get(\"types\") or []\n    if isinstance(lead_types, str):\n        lead_types = [lead_types]\n    lead_types = [str(t).strip().upper() for t in lead_types if t]\n\n    super_eff = 0\n    for at in atk_types:\n        mult = _type_multiplier(at, lead_types)\n        if mult > 1.0:\n            super_eff += 1\n    f[\"lead_type_coverage_score\"] = float(super_eff)\n\n    # ---------------------------------\n    # 2) Lead bulk index gap\n    #    \"How much bulkier is P1 team compared to the opponent lead?\"\n    # ---------------------------------\n    p1_def_vals = []\n    p1_spd_vals = []\n    for p in t1 or []:\n        if isinstance(p, dict):\n            d = p.get(\"base_def\", 0)\n            s = p.get(\"base_spd\", 0)\n            if isinstance(d, (int, float)):\n                p1_def_vals.append(float(d))\n            if isinstance(s, (int, float)):\n                p1_spd_vals.append(float(s))\n    p1_bulk = _safe_mean(p1_def_vals) + _safe_mean(p1_spd_vals)\n\n    lead_def = float(lead.get(\"base_def\", 0.0) or 0.0)\n    lead_spd = float(lead.get(\"base_spd\", 0.0) or 0.0)\n    lead_bulk = lead_def + lead_spd\n\n    f[\"lead_bulk_index_gap\"] = float(p1_bulk - lead_bulk)\n\n    # ---------------------------------\n    # 3) Early HP domination ratio (first 5 turns)\n    #    \"How often is P1 ahead in HP in the early game?\"\n    # ---------------------------------\n    k = 5\n    p1_5 = p1[:k]\n    p2_5 = p2[:k]\n    if p1_5 and p2_5 and len(p1_5) == len(p2_5):\n        ahead = sum(1 for a, b in zip(p1_5, p2_5) if a > b)\n        f[\"early_hp_domination_ratio_5\"] = float(ahead) / max(1, len(p1_5))\n    else:\n        f[\"early_hp_domination_ratio_5\"] = 0.0\n\n    # ---------------------------------\n    # 4) HP swing between early and mid game (first 5 vs last 5 turns)\n    #    \"Did the HP advantage improve or deteriorate over time?\"\n    # ---------------------------------\n    if p1 and p2 and len(p1) == len(p2) and len(p1) >= 6:\n        diff = [float(a) - float(b) for a, b in zip(p1, p2)]\n        first_5 = diff[:5]\n        last_5  = diff[-5:]\n        swing = _safe_mean(last_5) - _safe_mean(first_5)\n        f[\"hp_swing_10\"] = float(swing)\n    else:\n        f[\"hp_swing_10\"] = 0.0\n\n    # ---------------------------------\n    # 5) Speed coverage margin\n    #    \"How many of P1's mons outspeed the lead by >10 base speed?\"\n    # ---------------------------------\n    lead_spe = float(lead.get(\"base_spe\", 0.0) or 0.0)\n    faster_strict = 0\n    for p in t1 or []:\n        if not isinstance(p, dict):\n            continue\n        v = p.get(\"base_spe\", None)\n        if isinstance(v, (int, float)) and float(v) > lead_spe + 10.0:\n            faster_strict += 1\n    f[\"speed_coverage_margin\"] = float(faster_strict)\n\n    return f\n\n\n# ====================================\n# LEAD MATCHUP / DAMAGE-INDEX HELPERS\n# ====================================\ndef _simple_damage_index(base_power: float, stab: bool, eff: float, atk_proxy: float, def_proxy: float) -> float:\n    if not isinstance(base_power, (int, float)) or base_power <= 0:\n        return 0.0\n    s = 1.5 if stab else 1.0\n    ratio = (float(atk_proxy) + 1e-3) / (float(def_proxy) + 1e-3)\n    val = float(base_power) * s * float(eff) * ratio\n    return float(val) if np.isfinite(val) else 0.0\n\ndef _p1_vs_p2lead_matchup_index(record: dict, tl: list[dict]) -> dict:\n    p1_team = record.get(\"p1_team_details\", []) or []\n    p1_mean_atk = float(np.mean([p.get(\"base_atk\", 0) for p in p1_team])) if p1_team else 0.0\n    p1_mean_spa = float(np.mean([p.get(\"base_spa\", 0) for p in p1_team])) if p1_team else 0.0\n\n    lead = record.get(\"p2_lead_details\") or {}\n    p2_types = lead.get(\"types\") or []\n    if isinstance(p2_types, str): p2_types = [p2_types]\n    p2_types = [t for t in p2_types if t]\n    p2_def = float(lead.get(\"base_def\", 0.0) or 0.0)\n    p2_spd = float(lead.get(\"base_spd\", 0.0) or 0.0)\n\n    p1map = {}\n    for p in p1_team:\n        nm = (p.get(\"name\") or \"\").strip().lower()\n        ts = p.get(\"types\") or []\n        if isinstance(ts, str): ts = [ts]\n        p1map[nm] = {str(x).strip().upper() for x in ts if x}\n\n    def _acc(window=None):\n        seq = tl if window is None else tl[:window]\n        vals = []\n        for t in seq:\n            md = t.get(\"p1_move_details\") or {}\n            bp = md.get(\"base_power\"); cat = md.get(\"category\"); mtype = md.get(\"type\")\n            if not isinstance(bp, (int, float)) or bp <= 0: \n                continue\n            nm = (t.get(\"p1_pokemon_state\") or {}).get(\"name\", \"\")\n            nm = (nm or \"\").strip().lower()\n            is_stab = str(mtype or \"\").strip().upper() in p1map.get(nm, set())\n            eff = _type_multiplier(mtype, p2_types)\n            if (cat or \"\").upper() == \"PHYSICAL\":\n                idx = _simple_damage_index(bp, is_stab, eff, p1_mean_atk, p2_def)\n            elif (cat or \"\").upper() == \"SPECIAL\":\n                idx = _simple_damage_index(bp, is_stab, eff, p1_mean_spa, p2_spd)\n            else:\n                idx = 0.0\n            vals.append(idx)\n        return float(np.mean(vals)) if vals else 0.0\n\n    return {\n        \"lead_matchup_p1_index_full\": _acc(None),\n        \"lead_matchup_p1_index_5\":    _acc(5),\n    }\n\n# ==========================\n# SWITCH / HAZARD / MOMENTUM\n# ==========================\ndef _switch_count(tl: list[dict], who: str) -> float:\n    last = None\n    cnt = 0\n    key = f\"{who}_pokemon_state\"\n    for t in tl:\n        nm = (t.get(key) or {}).get(\"name\")\n        if nm is None:\n            continue\n        if last is not None and nm != last:\n            cnt += 1\n        last = nm\n    return float(cnt)\n\nHAZARD_MOVES = {\"stealthrock\", \"spikes\", \"toxicspikes\", \"stickyweb\"}\n\ndef _hazard_flags(tl: list[dict]) -> dict:\n    p1 = p2 = 0.0\n    for t in tl:\n        m1 = (t.get(\"p1_move_details\") or {}).get(\"name\")\n        m2 = (t.get(\"p2_move_details\") or {}).get(\"name\")\n        if m1 and str(m1).strip().lower() in HAZARD_MOVES: p1 = 1.0\n        if m2 and str(m2).strip().lower() in HAZARD_MOVES: p2 = 1.0\n    return {\"hazard_p1_flag\": p1, \"hazard_p2_flag\": p2, \"hazard_flag_diff\": p1 - p2}\n\ndef _momentum_shift(tl: list[dict], t1: int = 3, t2: int = 10) -> dict:\n    def _hp_diff_mean(win):\n        p1, p2 = _extract_hp_series(win)\n        if not p1 or not p2 or len(p1) != len(p2): return 0.0\n        d = [a-b for a,b in zip(p1,p2)]\n        return float(np.mean(d)) if d else 0.0\n    d1 = _hp_diff_mean(tl[:t1]); d2 = _hp_diff_mean(tl[:t2])\n    return {\"momentum_shift_3_10\": float(d1 - d2), \"momentum_shift_abs_3_10\": float(abs(d1 - d2))}\n\nHEAL_MOVES = {\"recover\",\"roost\",\"softboiled\",\"rest\",\"wish\",\"synthesis\",\"morningsun\",\"moonlight\",\"drainpunch\",\"leechseed\"}\n\ndef _recovery_pressure(tl: list[dict]) -> dict:\n    p1 = p2 = 0.0\n    for t in tl:\n        m1 = (t.get(\"p1_move_details\") or {}).get(\"name\")\n        m2 = (t.get(\"p2_move_details\") or {}).get(\"name\")\n        if m1 and str(m1).strip().lower() in HEAL_MOVES: p1 += 1.0\n        if m2 and str(m2).strip().lower() in HEAL_MOVES: p2 += 1.0\n    return {\"recover_p1_count\": p1, \"recover_p2_count\": p2, \"recover_count_diff\": p1 - p2}\n\n# ---------------------------------------------\n# NEW FEATURES \n# ---------------------------------------------\ndef new_features(r):\n    tl = get_timeline(r, max_turns=30)\n    p1, p2 = _extract_hp_series(tl)\n    t1 = r.get(\"p1_team_details\", []) or []\n    lead = r.get(\"p2_lead_details\", {}) or {}\n\n    f = {}\n    if len(p1) >= 3 and len(p2) >= 3:\n        f['early_hp_winner'] = 1.0 if np.mean(p1[:3]) > np.mean(p2[:3]) else 0.0\n        f['early_hp_difference'] = np.mean(p1[:3]) - np.mean(p2[:3])\n\n    if p1 and p2:\n        f['final_hp_winner'] = 1.0 if p1[-1] > p2[-1] else 0.0\n        f['final_hp_difference'] = p1[-1] - p2[-1]\n\n    p1_total_stats = sum(p.get(k, 0) for p in t1 for k in BASE_STAT_KEYS)\n    p2_total_stats = sum(lead.get(k, 0) for k in BASE_STAT_KEYS)\n    f['stronger_team'] = 1.0 if p1_total_stats > p2_total_stats else 0.0\n    f['team_strength_gap'] = p1_total_stats - p2_total_stats\n\n    p1_speeds = [p.get('base_spe', 0) for p in t1]\n    p2_speed = lead.get('base_spe', 0)\n    f['faster_team'] = 1.0 if max(p1_speeds, default=0) > p2_speed else 0.0\n    f['speed_advantage'] = max(p1_speeds, default=0) - p2_speed\n    f['num_faster_pokemon'] = sum(1 for s in p1_speeds if s > p2_speed)\n\n    f['p1_danger_count'] = sum(1 for hp in p1 if 0 < hp < 25)\n    f['p2_danger_count'] = sum(1 for hp in p2 if 0 < hp < 25)\n    f['survived_more_danger'] = 1.0 if f['p1_danger_count'] < f['p2_danger_count'] else 0.0\n    return f\n\n# ---------------------------------------------\n# Mirko & Deb\n# ---------------------------------------------\ndef get_defensive_profile(types):\n    \"\"\"\n    Combined defensive multipliers for a defender with 'types' against every attack type.\n    Fixed: use attacking type first, then multiply by defender types.\n    \"\"\"\n    types = types or []\n    if isinstance(types, str): types = [types]\n    types_up = [str(t).strip().upper() for t in types if t]\n\n    combined = {}\n    for atk_type in _TYPE_CHART.keys():\n        mult = 1.0\n        for tdef in types_up:\n            mult *= _TYPE_CHART.get(atk_type, {}).get(tdef, 1.0)\n        combined[atk_type] = float(mult)\n    return combined\ndef _team_max_eff_vs_lead(team: list[dict], lead_types_raw) -> float:\n    \"\"\"\n    For a given P1 team and the P2 lead types, compute the maximum\n    type effectiveness multiplier the team can theoretically have\n    against that lead, using each Pokémon's own typing as proxy\n    for its offensive coverage.\n    \"\"\"\n    # Normalize lead types\n    lead_types = lead_types_raw or []\n    if isinstance(lead_types, str):\n        lead_types = [lead_types]\n    lead_types = [t for t in lead_types if t]\n\n    if not team or not lead_types:\n        return 1.0  # neutral\n\n    best = 1.0\n    for p in team:\n        if not isinstance(p, dict):\n            continue\n        ts = p.get(\"types\") or []\n        if isinstance(ts, str):\n            ts = [ts]\n        ts = [str(t).strip().upper() for t in ts if t]\n        if not ts:\n            continue\n        # for each offensive type (we approximate using its own typing)\n        local_best = 1.0\n        for atk_type in ts:\n            eff = _type_multiplier(atk_type, lead_types)\n            if eff > local_best:\n                local_best = eff\n        if local_best > best:\n            best = local_best\n    return float(best)\n\ndef new_features_mirko(battle):\n    features = {}\n    # Player 1 Team aggregate\n    p1_team = battle.get('p1_team_details', []) or []\n    if p1_team:\n        ratios = []\n        v_hp=[]; v_spe=[]; v_atk=[]; v_def=[]\n        all_types=[]\n        weaknesses=[]; resistances=[]; immunities=[]\n        for p in p1_team:\n            if not isinstance(p, dict): \n                continue\n            off = (p.get(\"base_atk\",0) + p.get(\"base_spa\",0))\n            deff = (p.get(\"base_def\",0) + p.get(\"base_spd\",0))\n            ratios.append(off / deff if deff > 0 else 0.0)\n\n            v_hp.append(p.get('base_hp',0)); v_spe.append(p.get('base_spe',0))\n            v_atk.append(p.get('base_atk',0)); v_def.append(p.get('base_def',0))\n\n            ts = p.get(\"types\") or []\n            if isinstance(ts,str): ts=[ts]\n            all_types.extend([t for t in ts if str(t).lower()!='notype'])\n\n            prof = get_defensive_profile(ts)\n            w = sum(1 for m in prof.values() if m > 1)\n            r = sum(1 for m in prof.values() if 0 < m < 1)\n            i = sum(1 for m in prof.values() if m == 0)\n            weaknesses.append(w); resistances.append(r); immunities.append(i)\n\n        features[\"avg_type_role_ratio\"] = float(np.mean(ratios)) if ratios else 0.0\n        features['p1_var_hp']  = float(np.std(v_hp)) if v_hp else 0.0\n        features['p1_var_spe'] = float(np.std(v_spe)) if v_spe else 0.0\n        features['p1_var_atk'] = float(np.std(v_atk)) if v_atk else 0.0\n        features['p1_var_def'] = float(np.std(v_def)) if v_def else 0.0\n\n        unique_types = len(set(all_types))\n        features['diversity_ratio'] = unique_types / 6.0\n\n        features[\"avg_weaknesses\"] = float(np.mean(weaknesses))  if weaknesses  else 0.0\n        features[\"avg_resistances\"] = float(np.mean(resistances)) if resistances else 0.0\n        features[\"avg_immunities\"] = float(np.mean(immunities))  if immunities  else 0.0\n\n    # P2 lead raw stats\n    p2_lead = battle.get('p2_lead_details') or {}\n    if isinstance(p2_lead, dict) and p2_lead:\n        features['p2_lead_hp']  = p2_lead.get('base_hp', 0)\n        features['p2_lead_spe'] = p2_lead.get('base_spe', 0)\n        features['p2_lead_atk'] = p2_lead.get('base_atk', 0)\n        features['p2_lead_def'] = p2_lead.get('base_def', 0)\n\n    # Voluntary leave counters (None move_details ~ skipped)\n    tl = battle.get('battle_timeline', []) or []\n    idx_none_p2 = [i+1 for i,e in enumerate(tl) if e.get('p2_move_details') is None]\n    idx_none_p1 = [i+1 for i,e in enumerate(tl) if e.get('p1_move_details') is None]\n    def _bucket_count(idxs,a,b): return len([x for x in idxs if a<=x<=b])\n    features['vol_leave_diff_1'] = _bucket_count(idx_none_p1,1,10)  - _bucket_count(idx_none_p2,1,10)\n    features['vol_leave_diff_2'] = _bucket_count(idx_none_p1,11,20) - _bucket_count(idx_none_p2,11,20)\n    features['vol_leave_diff_3'] = _bucket_count(idx_none_p1,21,10**9) - _bucket_count(idx_none_p2,21,10**9)\n\n    # Forced leave heuristics (name change + action executed)\n    def _forced_counts(side_key, move_key):\n        lst=[]\n        for t in tl:\n            lst.append([ (t.get(side_key) or {}).get(\"name\"), (t.get(move_key) is None) ])\n        c1=c2=c3=0\n        for i in range(len(lst)-1):\n            changed = (lst[i+1][0] != lst[i][0])\n            acted   = (lst[i+1][1] == False)\n            turn_idx = i+1\n            if changed and acted:\n                if 1<=turn_idx<=10: c1+=1\n                elif 11<=turn_idx<=20: c2+=1\n                else: c3+=1\n        return c1,c2,c3\n    p1c1,p1c2,p1c3 = _forced_counts(\"p1_pokemon_state\",\"p1_move_details\")\n    p2c1,p2c2,p2c3 = _forced_counts(\"p2_pokemon_state\",\"p2_move_details\")\n    features['forced_leave_diff_1'] = float(p1c1 - p2c1)\n    features['forced_leave_diff_2'] = float(p1c2 - p2c2)\n    features['forced_leave_diff_3'] = float(p1c3 - p2c3)\n\n    # IDs / target\n    features['battle_id'] = battle.get('battle_id')\n    if 'player_won' in battle: features['player_won'] = int(battle['player_won'])\n    return features\n\n# ======= helpers for team & HP & damage stats =======\ndef _pnames_from_p1_team(record):\n    team = record.get(\"p1_team_details\", []) or []\n    names = []\n    for p in team:\n        if isinstance(p, dict):\n            nm = (p.get(\"name\") or \"\").strip().lower()\n            if nm: names.append(nm)\n    return names\n\ndef _pname_from_p2_lead(record):\n    lead = record.get(\"p2_lead_details\") or {}\n    if isinstance(lead, dict):\n        nm = (lead.get(\"name\") or \"\").strip().lower()\n        return nm if nm else None\n    return None\n\ndef build_pokemon_win_stats(train_data, alpha=1.0):\n    games = defaultdict(int); wins = defaultdict(int)\n    for r in train_data:\n        p1_names = _pnames_from_p1_team(r)\n        p2_lead  = _pname_from_p2_lead(r)\n        p1_won   = bool(r.get(\"player_won\", False))\n        for nm in p1_names: games[nm]+=1\n        if p2_lead: games[p2_lead]+=1\n        if p1_won:\n            for nm in p1_names: wins[nm]+=1\n        else:\n            if p2_lead: wins[p2_lead]+=1\n    winrate={}\n    for nm in games:\n        g=games[nm]; w=wins[nm]\n        wr=(w+alpha)/(g+2*alpha)\n        winrate[nm]={\"games\":g,\"wins\":w,\"winrate\":wr}\n    return winrate\n\ndef team_score_from_stats(team_names, stats, default_wr=0.5):\n    vals=[stats.get((nm or \"\").strip().lower(),{}).get(\"winrate\",default_wr) for nm in team_names if nm]\n    return float(np.mean(vals)) if vals else default_wr\n\ndef predict_from_stats(test_record, stats, threshold=0.5):\n    p1_names = _pnames_from_p1_team(test_record)\n    score = team_score_from_stats(p1_names, stats, default_wr=0.5)\n    return (score > threshold), score\n\ndef build_pokemon_hp_stats(train_data):\n    hp_sum=defaultdict(float); hp_count=defaultdict(int)\n    for r in train_data:\n        timeline = r.get(\"battle_timeline\", []) or []\n        if not timeline: continue\n        last_turn = timeline[-1]\n        for player_key in [\"p1_pokemon_state\", \"p2_pokemon_state\"]:\n            name = (last_turn.get(player_key, {}).get(\"name\") or \"\").strip().lower()\n            hp   = last_turn.get(player_key, {}).get(\"hp_pct\", None)\n            if name and isinstance(hp,(int,float)):\n                hp_sum[name]+=float(hp); hp_count[name]+=1\n    stats = {name: {\"count\": hp_count[name], \"hp_mean\": hp_sum[name]/hp_count[name]} for name in hp_sum}\n    return stats\n\ndef team_hp_score(team_names, hp_stats, default_hp=50.0):\n    vals=[]\n    for name in team_names:\n        n=(name or \"\").strip().lower()\n        vals.append(hp_stats.get(n,{}).get(\"hp_mean\", default_hp))\n    return float(np.mean(vals)) if vals else default_hp\n\ndef build_pokemon_avg_damage(train_data):\n    total_damage=defaultdict(float); battles_count=defaultdict(int)\n    for battle in train_data:\n        timeline = battle.get(\"battle_timeline\", []) or []\n        p1_names = [(p.get(\"name\") or \"\").lower() for p in (battle.get(\"p1_team_details\", []) or []) if isinstance(p,dict)]\n        p2_lead  = battle.get(\"p2_lead_details\", {})\n        p2_name  = (p2_lead.get(\"name\") or \"\").lower() if isinstance(p2_lead,dict) else None\n\n        for name in p1_names: battles_count[name]+=1\n        if p2_name: battles_count[p2_name]+=1\n\n        for i in range(1,len(timeline)):\n            prev, curr = timeline[i-1], timeline[i]\n            hp2b = (prev.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\", None)\n            hp2a = (curr.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\", None)\n            if isinstance(hp2b,(int,float)) and isinstance(hp2a,(int,float)):\n                dmg=max(0,hp2b-hp2a)\n                if p1_names and dmg>0:\n                    for name in p1_names: total_damage[name]+=dmg\n            hp1b = (prev.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\", None)\n            hp1a = (curr.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\", None)\n            if isinstance(hp1b,(int,float)) and isinstance(hp1a,(int,float)):\n                dmg=max(0,hp1b-hp1a)\n                if p2_name and dmg>0:\n                    total_damage[p2_name]+=dmg\n    avg_damage = {name: total_damage[name]/battles_count[name] for name in battles_count if battles_count[name]>0}\n    return avg_damage\n\ndef damage_feature_for_battle(record, avg_damage):\n    p1_names = [(p.get(\"name\") or \"\").lower() for p in (record.get(\"p1_team_details\",[]) or []) if isinstance(p,dict)]\n    p1_damage_score = sum(avg_damage.get(name, 0.0) for name in p1_names)\n    p2_lead = record.get(\"p2_lead_details\", {}) or {}\n    p2_name = (p2_lead.get(\"name\") or \"\").lower() if isinstance(p2_lead,dict) else None\n    p2_damage_score = avg_damage.get(p2_name,0.0) if p2_name else 0.0\n    diff = p1_damage_score - p2_damage_score\n    return {\"avg_damage_p1\": p1_damage_score, \"avg_damage_p2\": p2_damage_score, \"avg_damage_diff\": diff, \"damage_prediction\": 1.0 if diff>0 else 0.0}\n\n# ======= Deb's feature block (kept) =======\ndef new_features_deb(r):\n    tl = get_timeline(r, max_turns=30)\n    p1, p2 = _extract_hp_series(tl)\n    t1 = r.get(\"p1_team_details\", []) or []\n    lead = r.get(\"p2_lead_details\", {}) or {}\n    f = {}\n\n    if len(p1) >= 3 and len(p2) >= 3:\n        media_p1 = float(np.mean(p1[:3])); media_p2 = float(np.mean(p2[:3]))\n        f['is_p1_higher_avg_hp_after_3_turns'] = 1.0 if media_p1 > media_p2 else 0.0\n        f['avg_hp_difference_after_3_turns'] = media_p1 - media_p2\n\n    if p1 and p2:\n        f['is_player1_final_hp_winner'] = 1.0 if p1[-1] > p2[-1] else 0.0\n        f['final_hp_difference'] = p1[-1] - p2[-1]\n\n    if len(p1) >= 6 and len(p2) >= 6:\n        f['comeback_happened'] = float((np.mean(p1[:3]) > np.mean(p2[:3])) != (np.mean(p1[-3:]) > np.mean(p2[-3:])))\n\n    p1_total_stats = sum(p.get('base_hp',0)+p.get('base_atk',0)+p.get('base_def',0)+p.get('base_spa',0)+p.get('base_spd',0)+p.get('base_spe',0) for p in t1 if isinstance(p,dict))\n    p2_total_stats = (lead.get('base_hp',0)+lead.get('base_atk',0)+lead.get('base_def',0)+lead.get('base_spa',0)+lead.get('base_spd',0)+lead.get('base_spe',0))\n    f['stronger_team'] = 1.0 if p1_total_stats > p2_total_stats else 0.0\n    f['team_strength_gap'] = p1_total_stats - p2_total_stats\n\n    p1_speeds = [p.get('base_spe', 0) for p in t1 if isinstance(p,dict)]\n    p2_speed = lead.get('base_spe', 0) if isinstance(lead,dict) else 0\n    if p1_speeds:\n        f['faster_team'] = 1.0 if max(p1_speeds) > p2_speed else 0.0\n        f['speed_advantage'] = max(p1_speeds) - p2_speed\n        f['num_faster_pokemon'] = sum(1 for s in p1_speeds if s > p2_speed)\n    else:\n        f['faster_team'] = 0.0; f['speed_advantage'] = 0.0; f['num_faster_pokemon'] = 0.0\n\n    p1_powers=[]; p2_powers=[]\n    for t in tl:\n        if not isinstance(t,dict): continue\n        md1=t.get('p1_move_details'); md2=t.get('p2_move_details')\n        bp1 = md1.get('base_power') if isinstance(md1,dict) else None\n        bp2 = md2.get('base_power') if isinstance(md2,dict) else None\n        if isinstance(bp1,(int,float)) and bp1>0: p1_powers.append(float(bp1))\n        if isinstance(bp2,(int,float)) and bp2>0: p2_powers.append(float(bp2))\n    if p1_powers and p2_powers:\n        f['most_avg_powerful_move'] = 1.0 if np.mean(p1_powers) > np.mean(p2_powers) else 0.0\n        f['avg_move_power_difference'] = float(np.mean(p1_powers) - np.mean(p2_powers))\n    else:\n        f['most_avg_powerful_move'] = 0.0; f['avg_move_power_difference'] = 0.0\n\n    f['p1_low_hp_count'] = sum(1 for hp in p1 if 0 < hp < 25)\n    f['p2_low_hp_count'] = sum(1 for hp in p2 if 0 < hp < 25)\n    f['is_player1_less_time_in_danger'] = 1.0 if f['p1_low_hp_count'] < f['p2_low_hp_count'] else 0.0\n    f['battle_length'] = len(tl)\n    f['long_battle'] = 1.0 if len(tl) > 15 else 0.0\n\n    if len(p1) > 1 and len(p2) > 1:\n        p1_changes=[abs(p1[i]-p1[i-1]) for i in range(1,len(p1))]\n        p2_changes=[abs(p2[i]-p2[i-1]) for i in range(1,len(p2))]\n        f['p1_hp_stability'] = -float(np.mean(p1_changes)) if p1_changes else 0.0\n        f['p2_hp_stability'] = -float(np.mean(p2_changes)) if p2_changes else 0.0\n        f['more_stable_hp'] = 1.0 if (p1_changes and p2_changes and np.mean(p1_changes) < np.mean(p2_changes)) else 0.0\n    else:\n        f['p1_hp_stability']=0.0; f['p2_hp_stability']=0.0; f['more_stable_hp']=0.0\n\n    p1_first_ko=0.0; p2_first_ko=0.0\n    for hp1,hp2 in zip(p1,p2):\n        if hp2==0 and p2_first_ko==0.0: p2_first_ko=1.0; break\n        if hp1==0 and p1_first_ko==0.0: p1_first_ko=1.0; break\n    f['player1_got_first_ko']=p2_first_ko\n    f['player1_suffered_first_ko']=p1_first_ko\n\n    p1_types=set()\n    for p in t1:\n        if not isinstance(p,dict): continue\n        types=p.get('types',[])\n        if isinstance(types,str): types=[types]\n        p1_types.update(t for t in types if t)\n    f['number_different_types']=len(p1_types)\n    f['team_has_type_variety']=1.0 if len(p1_types)>=4 else 0.0\n\n    if p1 and p2:\n        p1_healthy_ratio = sum(1 for hp in p1 if hp>50)/len(p1)\n        p2_healthy_ratio = sum(1 for hp in p2 if hp>50)/len(p2)\n        f['p1_hp_over_50_ratio']=p1_healthy_ratio\n        f['p2_hp_over_50_ratio']=p2_healthy_ratio\n        f['is_player1_healthier']=1.0 if p1_healthy_ratio>p2_healthy_ratio else 0.0\n    else:\n        f['p1_hp_over_50_ratio']=0.0; f['p2_hp_over_50_ratio']=0.0; f['is_player1_healthier']=0.0\n\n    if len(p1)==len(p2) and p1:\n        turns_ahead=sum(1 for a,b in zip(p1,p2) if a>b)\n        f['turns_in_lead']=float(turns_ahead)\n        f['lead_ratio']=turns_ahead/len(p1)\n        f['dominated_battle']=1.0 if turns_ahead>len(p1)*0.7 else 0.0\n    else:\n        f['turns_in_lead']=0.0; f['lead_ratio']=0.0; f['dominated_battle']=0.0\n\n    p_leave = r.get('battle_timeline', []) or []\n    if p_leave:\n        lst=[]; c1=c2=0\n        for turn in p_leave:\n            lst.append([\n                (turn.get(\"p1_pokemon_state\") or {}).get(\"name\"),\n                (turn.get('p1_move_details') is None),\n                (turn.get(\"p2_pokemon_state\") or {}).get(\"name\"),\n                (turn.get('p2_move_details') is None)\n            ])\n        for i in range(len(lst)-1):\n            if lst[i+1][0]!=lst[i][0] and lst[i+1][1]==False: c1+=1\n            elif lst[i+1][2]!=lst[i][2] and lst[i+1][3]==False: c2+=1\n        f['forced_pokemon_switch_diff']=float(c1-c2)\n    else:\n        f['forced_pokemon_switch_diff']=0.0\n\n    if p_leave:\n        p1_names=set([ (t.get(\"p1_pokemon_state\") or {}).get(\"name\") for t in p_leave if (t.get(\"p1_pokemon_state\") or {}).get(\"name\") ])\n        p2_names=set([ (t.get(\"p2_pokemon_state\") or {}).get(\"name\") for t in p_leave if (t.get(\"p2_pokemon_state\") or {}).get(\"name\") ])\n        f['used_pokemon_diff']=float(len(p1_names)-len(p2_names))\n    else:\n        f['used_pokemon_diff']=0.0\n\n    if p_leave:\n        recent=p_leave[-5:] if len(p_leave)>=5 else p_leave\n        p1r=[(t.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0) for t in recent]\n        p2r=[(t.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0) for t in recent]\n        f['avg_hp_recent_diff']=float(np.mean(p1r)-np.mean(p2r)) if p1r and p2r else 0.0\n    else:\n        f['avg_hp_recent_diff']=0.0\n\n    if p_leave:\n        p1_status=sum(1 for t in p_leave if (t.get(\"p1_pokemon_state\") or {}).get(\"status\",\"nostatus\")!=\"nostatus\")\n        p2_status=sum(1 for t in p_leave if (t.get(\"p2_pokemon_state\") or {}).get(\"status\",\"nostatus\")!=\"nostatus\")\n        f['num_bad_status_diff']=float(p2_status-p1_status)\n    else:\n        f['num_bad_status_diff']=0.0\n\n    if p_leave:\n        last=p_leave[-1]\n        p1f=(last.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0)\n        p2f=(last.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0)\n        f['final_hp_diff']=float(p1f-p2f)\n        p1_alive = 1 if p1f>0 else 0\n        p2_alive = 1 if p2f>0 else 0\n        p1_used=len(set([(t.get(\"p1_pokemon_state\") or {}).get(\"name\") for t in p_leave if (t.get(\"p1_pokemon_state\") or {}).get(\"name\")]))\n        p2_used=len(set([(t.get(\"p2_pokemon_state\") or {}).get(\"name\") for t in p_leave if (t.get(\"p2_pokemon_state\") or {}).get(\"name\")]))\n        team_size=6\n        p1_remaining = team_size - p1_used + p1_alive\n        p2_remaining = team_size - p2_used + p2_alive\n        f['pokemon_remaining_diff']=float(p1_remaining - p2_remaining)\n    else:\n        f['final_hp_diff']=0.0; f['pokemon_remaining_diff']=0.0\n\n    if p_leave and len(p_leave)>=2:\n        total_dmg_dealt=0.0; total_dmg_taken=0.0\n        for i in range(1,len(p_leave)):\n            prev, curr = p_leave[i-1], p_leave[i]\n            p2b=(prev.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0)\n            p2a=(curr.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0)\n            total_dmg_dealt += max(0,p2b-p2a)\n            p1b=(prev.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0)\n            p1a=(curr.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0)\n            total_dmg_taken += max(0,p1b-p1a)\n        f['damage_ratio'] = float(total_dmg_dealt/total_dmg_taken) if total_dmg_taken>0 else (total_dmg_dealt*10 if total_dmg_dealt>0 else 1.0)\n        f['tot_damage_diff']=float(total_dmg_dealt-total_dmg_taken)\n    else:\n        f['damage_ratio']=1.0; f['tot_damage_diff']=0.0\n\n    if p_leave and len(p_leave)>=6:\n        mid=len(p_leave)//2\n        first=p_leave[:mid]; second=p_leave[mid:]\n        p1e=[(t.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0) for t in first]\n        p2e=[(t.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0) for t in first]\n        p1l=[(t.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0) for t in second]\n        p2l=[(t.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0) for t in second]\n        early_adv = float(np.mean(p1e)-np.mean(p2e)) if p1e and p2e else 0.0\n        late_adv  = float(np.mean(p1l)-np.mean(p2l)) if p1l and p2l else 0.0\n        f['late_game_improvement']=late_adv - early_adv\n        f['late_game_hp_adv']=late_adv\n        f['early_game_hp_adv']=early_adv\n    else:\n        f['late_game_improvement']=0.0; f['late_game_hp_adv']=0.0; f['early_game_hp_adv']=0.0\n\n    if len(p1)>=10 and len(p2)>=10:\n        f['avg_hp_diff_gap'] = float( (np.mean(p1[5:10]) - np.mean(p2[5:10])) - (np.mean(p1[:5]) - np.mean(p2[:5])) )\n\n    if len(p1)>3 and len(p2)>3:\n        f['p1_hp_std']=float(np.std(np.diff(p1)))\n        f['p2_hp_std']=float(np.std(np.diff(p2)))\n\n    if p1 and p2:\n        f['max_hp_deficit_player1'] = float(max(0, max(p2) - min(p1)))\n\n    total_dealt=total_taken=0.0\n    for i in range(1,len(tl)):\n        prev, curr = tl[i-1], tl[i]\n        if not (isinstance(prev,dict) and isinstance(curr,dict)): continue\n        weight = 1.0 + (i/len(tl))*0.5\n        p2_prev=(prev.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",100)\n        p2_curr=(curr.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",100)\n        total_dealt += max(0,p2_prev-p2_curr)*weight\n        p1_prev=(prev.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",100)\n        p1_curr=(curr.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",100)\n        total_taken += max(0,p1_prev-p1_curr)*weight\n    f['damage_trade_ratio_weighted'] = float(total_dealt/max(1,total_taken))\n\n    if tl:\n        last=tl[-1]\n        p1f=(last.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0)\n        p2f=(last.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0)\n        f['final_hp_advantage']=float(p1f-p2f)\n        f['final_hp_ratio']=float(p1f/max(1,p2f))\n        p1_last_pow=(last.get(\"p1_move_details\") or {}).get(\"base_power\",0)\n        p2_last_pow=(last.get(\"p2_move_details\") or {}).get(\"base_power\",0)\n        f['final_power_advantage']=float(p1_last_pow - p2_last_pow)\n        p1_status=(last.get(\"p1_pokemon_state\") or {}).get(\"status\",\"\")\n        p2_status=(last.get(\"p2_pokemon_state\") or {}).get(\"status\",\"\")\n        f['final_status_advantage']=0.0\n        if p2_status and str(p2_status).lower() not in [\"\",\"none\",\"nostatus\"]: f['final_status_advantage'] += 1.0\n        if p1_status and str(p1_status).lower() not in [\"\",\"none\",\"nostatus\"]: f['final_status_advantage'] -= 1.0\n\n        final_score = 0.0\n        final_score += (p1f - p2f) * 0.5\n        if p1f>0 and p2f==0: final_score += 30.0\n        elif p2f>0 and p1f==0: final_score -= 30.0\n        final_score += (p1_last_pow - p2_last_pow) * 0.15\n        final_score += f['final_status_advantage'] * 5.0\n        f['final_battle_score']=final_score\n        f['final_winning_prob']=1.0/(1.0+np.exp(-final_score/10.0))\n\n        recent=tl[-5:] if len(tl)>=5 else tl\n        diffs=[]\n        for t in recent:\n            p1h=(t.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0)\n            p2h=(t.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0)\n            diffs.append(p1h-p2h)\n        if diffs:\n            f['recent_avg_hp_advantage']=float(np.mean(diffs))\n            f['recent_hp_improving']=1.0 if len(diffs)>1 and diffs[-1]>diffs[0] else 0.0\n\n    if 'final_hp_advantage' in f and len(tl)>=5:\n        hp_gap=f['final_hp_advantage']\n        turns=len(tl)\n        comeback=0.35\n        if abs(hp_gap)>50: comeback=0.95\n        elif abs(hp_gap)>30: comeback=0.75\n        elif abs(hp_gap)>15: comeback=0.55\n        if turns<10: comeback*=0.8\n        elif turns>20: comeback*=1.2\n        comeback=min(1.0, comeback)\n        win_prob = 0.5 + (comeback*0.5) if hp_gap>0 else 0.5 - (comeback*0.5)\n        f['comeback_difficulty']=float(comeback)\n        f['predicted_win_prob']=float(win_prob)\n\n    if p1 and p2 and len(tl)>=3:\n        p1_current_hp=p1[-1]; p2_current_hp=p2[-1]\n        pattern_score=0.0\n        p1_kos=sum(1 for hp in p2 if hp==0); p2_kos=sum(1 for hp in p1 if hp==0)\n        ko_adv = p1_kos - p2_kos\n        if ko_adv>=2: pattern_score+=0.3\n        elif ko_adv==1: pattern_score+=0.15\n        elif ko_adv==-1: pattern_score-=0.15\n        elif ko_adv<=-2: pattern_score-=0.3\n        if len(p1)>=5 and len(p2)>=5:\n            p1_trend = np.mean(p1[-3:]) - np.mean(p1[-5:-2])\n            p2_trend = np.mean(p2[-3:]) - np.mean(p2[-5:-2])\n            if p1_trend>5 and p2_trend<-5: pattern_score+=0.2\n            elif p1_trend<-5 and p2_trend>5: pattern_score-=0.2\n\n        p1_used=set(); p2_used=set()\n        for t in tl:\n            if isinstance(t,dict):\n                p1n=(t.get(\"p1_pokemon_state\") or {}).get(\"name\",\"\")\n                p2n=(t.get(\"p2_pokemon_state\") or {}).get(\"name\",\"\")\n                if p1n: p1_used.add(p1n)\n                if p2n: p2_used.add(p2n)\n        team_size=6\n        p1_rem=team_size - len(p1_used) + (1 if p1_current_hp>0 else 0)\n        p2_rem=team_size - len(p2_used) + (1 if p2_current_hp>0 else 0)\n        pokemon_adv = p1_rem - p2_rem\n        if pokemon_adv>=2: pattern_score+=0.35\n        elif pokemon_adv==1: pattern_score+=0.20\n        elif pokemon_adv==-1: pattern_score-=0.20\n        elif pokemon_adv<=-2: pattern_score-=0.35\n\n        f['ko_advantage']=float(ko_adv)\n        f['estimated_pokemon_remaining_p1']=float(p1_rem)\n        f['estimated_pokemon_remaining_p2']=float(p2_rem)\n        f['pokemon_advantage']=float(pokemon_adv)\n        base_prob=0.5\n        if 'final_hp_advantage' in f: base_prob += (f['final_hp_advantage']/100.0)*0.3\n        base_prob += pattern_score*0.4\n        if 'predicted_win_prob' in f: base_prob = base_prob*0.7 + f['predicted_win_prob']*0.3\n        f['final_win_probability']=max(0.0,min(1.0,base_prob))\n\n    if 'final_win_probability' in f:\n        prob=f['final_win_probability']\n        confidence = abs(prob-0.5)*2\n        if f.get('p1_alive_final',0)==1 and f.get('p2_alive_final',0)==0: confidence=0.95\n        elif f.get('p1_alive_final',0)==0 and f.get('p2_alive_final',0)==1: confidence=0.95\n        f['prediction_confidence']=float(confidence)\n        if prob>0.75 and confidence>0.6: f['outcome_prediction']=2.0\n        elif prob>0.6: f['outcome_prediction']=1.0\n        elif prob<0.25 and confidence>0.6: f['outcome_prediction']=-2.0\n        elif prob<0.4: f['outcome_prediction']=-1.0\n        else: f['outcome_prediction']=0.0\n    return f\n\n# ---------------------------------------------\n# Global stats built on train_data \n# ---------------------------------------------\nPOKEMON_STATS    = build_pokemon_win_stats(train_data, alpha=1.0)\nPOKEMON_HP_STATS = build_pokemon_hp_stats(train_data)\npokemon_avg_damage = build_pokemon_avg_damage(train_data)\n\n# ---------------------------------------------\n# Full feature set (static + timeline + moves + Mirko & Deb)\n# ---------------------------------------------\ndef _one_record_features(r):\n    # Static team features\n    t1 = r.get(\"p1_team_details\", []) or []\n    lead = r.get(\"p2_lead_details\", {}) or {}\n    t2 = [lead] if isinstance(lead, dict) and lead else []\n\n    p1sz = len(t1); p2sz = len(t2)\n    p1u  = unique_types(t1); p2u = unique_types(t2)\n    p1s  = sum_stats_of_team(t1); p2s = sum_stats_of_team(t2)\n    p1a  = avg_stats_of_team(t1); p2a = avg_stats_of_team(t2)\n    p2_ls, p2_la = sum_and_avg_of_single(lead) if lead else (0.0, 0.0)\n    p1v  = team_stat_variance(t1)\n\n    f = {\n        \"p1_team_size\": p1sz, \"p2_team_size\": p2sz,\n        \"p1_unique_types\": p1u, \"p2_unique_types\": p2u,\n        \"p1_team_stat_sum\": p1s, \"p2_team_stat_sum\": p2s,\n        \"p1_team_stat_avg\": p1a, \"p2_team_stat_avg\": p2a,\n        \"diff_team_size\": p1sz - p2sz,\n        \"diff_unique_types\": p1u - p2u,\n        \"diff_team_stat_sum\": p1s - p2s,\n        \"diff_team_stat_avg\": p1a - p2a,\n        \"p2_lead_stat_sum\": p2_ls, \"p2_lead_stat_avg\": p2_la,\n        \"p1_sum_minus_p2_lead_sum\": p1s - p2_ls,\n        \"p1_avg_minus_p2_lead_avg\": p1a - p2_la,\n        \"p1_team_stat_var\": p1v,\n        \"ratio_p1_avg_over_p2_lead_avg\": _safe_ratio(p1a, p2_la),\n    }\n\n    # Speed advantage vs p2 lead\n    p1_mean_spe, p1_max_spe = _team_speed_stats(t1)\n    p2_lead_spe = float(lead.get(\"base_spe\", 0.0)) if lead else 0.0\n    faster_cnt = sum(1 for p in t1 if isinstance(p.get(\"base_spe\"),(int,float)) and float(p[\"base_spe\"])>p2_lead_spe)\n    frac_faster = float(faster_cnt)/max(1,len(t1))\n    f.update({\n        \"p1_mean_spe\": p1_mean_spe, \"p1_max_spe\": p1_max_spe, \"p2_lead_spe\": p2_lead_spe,\n        \"spe_mean_adv\": p1_mean_spe - p2_lead_spe, \"spe_max_adv\": p1_max_spe - p2_lead_spe,\n        \"p1_frac_faster_than_p2lead\": frac_faster,\n    })\n\n    # Timeline HP features\n    tl = get_timeline(r, max_turns=30)\n    p1, p2 = _extract_hp_series(tl)\n    diff = [a-b for a,b in zip(p1,p2)] if p1 and p2 and len(p1)==len(p2) else []\n\n    p1m,p1l,p1s_,p1mn = _mean_last_std_min(p1)\n    p2m,p2l,p2s_,p2mn = _mean_last_std_min(p2)\n    dm,dl,ds,dmn = _mean_last_std_min(diff)\n\n    f.update({\n        \"tl_turns_used\": float(len(tl)),\n        \"tl_p1_hp_mean\": p1m, \"tl_p1_hp_last\": p1l, \"tl_p1_hp_std\": p1s_, \"tl_p1_hp_min\": p1mn,\n        \"tl_p2_hp_mean\": p2m, \"tl_p2_hp_last\": p2l, \"tl_p2_hp_std\": p2s_, \"tl_p2_hp_min\": p2mn,\n        \"tl_hp_diff_mean\": dm, \"tl_hp_diff_last\": dl, \"tl_hp_diff_std\": ds, \"tl_hp_diff_min\": dmn,\n        \"tl_p1_hp_slope\": _slope(p1), \"tl_p2_hp_slope\": _slope(p2), \"tl_hp_diff_slope\": _slope(diff),\n        \"tl_p1_hp_auc\": _auc_pct(p1), \"tl_p2_hp_auc\": _auc_pct(p2),\n        \"tl_frac_turns_advantage\": _frac_positive(diff),\n        \"tl_p1_status_count\": _status_count(tl,\"p1\"),\n        \"tl_p2_status_count\": _status_count(tl,\"p2\"),\n    })\n    f[\"tl_status_count\"] = f[\"tl_p1_status_count\"] + f[\"tl_p2_status_count\"]\n    f[\"tl_p1_ko_count\"]  = _ko_count(p1)\n    f[\"tl_p2_ko_count\"]  = _ko_count(p2)\n    f[\"tl_ko_count\"]     = f[\"tl_p1_ko_count\"] + f[\"tl_p2_ko_count\"]\n\n    # Type effectiveness P1 → P2 lead\n    p2_types = lead.get(\"types\") or []\n    if isinstance(p2_types,str): p2_types=[p2_types]\n    p2_types=[t for t in p2_types if t]\n    f.update({\n        \"ter_p1_vs_p2lead_full\": _avg_type_eff_p1_vs_p2lead(tl, p2_types, window=None),\n        \"ter_p1_vs_p2lead_5\":    _avg_type_eff_p1_vs_p2lead(tl, p2_types, window=5),\n        \"ter_p1_vs_p2lead_10\":   _avg_type_eff_p1_vs_p2lead(tl, p2_types, window=10),\n    })\n    # ------------------------------------------------------------------\n    # Extra matchup & tempo features (NEW)\n    # ------------------------------------------------------------------\n\n    # 1) Lead vs lead speed — who is faster?\n    # Try to use p1_lead_details if available, otherwise fallback to fastest team member.\n    p1_lead = r.get(\"p1_lead_details\") or {}\n    if isinstance(p1_lead, dict) and p1_lead:\n        lead_spe_p1 = float(p1_lead.get(\"base_spe\", 0.0) or 0.0)\n    else:\n        # fallback: use max speed in P1 team as \"effective lead speed\"\n        lead_spe_p1 = float(max([p.get(\"base_spe\", 0.0) for p in t1 if isinstance(p, dict)], default=0.0))\n\n    lead_spe_p2 = float(lead.get(\"base_spe\", 0.0) or 0.0) if lead else 0.0\n    f[\"lead_spe_p1\"] = lead_spe_p1\n    f[\"lead_spe_p2\"] = lead_spe_p2\n    f[\"lead_speed_adv\"] = lead_spe_p1 - lead_spe_p2\n    f[\"lead_is_faster\"] = 1.0 if lead_spe_p1 > lead_spe_p2 else 0.0\n\n    # 2) Hard counter vs P2 lead: maximum type effectiveness the P1 team\n    #    can theoretically achieve against the opponent lead.\n    max_eff_vs_lead = _team_max_eff_vs_lead(t1, p2_types)\n    f[\"team_max_eff_vs_p2lead\"] = max_eff_vs_lead\n    f[\"has_hard_counter_vs_lead\"] = 1.0 if max_eff_vs_lead >= 2.0 else 0.0\n    f[\"has_soft_counter_vs_lead\"] = 1.0 if max_eff_vs_lead >= 1.5 else 0.0\n\n    # 3) Late–game HP advantage (last 5 turns)\n    last_n = 5\n    if p1 and p2:\n        # slice last N turns safely\n        p1_lastN = p1[-last_n:] if len(p1) >= last_n else p1\n        p2_lastN = p2[-last_n:] if len(p2) >= last_n else p2\n        if p1_lastN and p2_lastN:\n            p1_lastN_mean = float(np.mean(p1_lastN))\n            p2_lastN_mean = float(np.mean(p2_lastN))\n            late_adv = p1_lastN_mean - p2_lastN_mean\n        else:\n            p1_lastN_mean = p2_lastN_mean = late_adv = 0.0\n    else:\n        p1_lastN_mean = p2_lastN_mean = late_adv = 0.0\n\n    f[\"late_hp_mean_p1_5\"] = p1_lastN_mean\n    f[\"late_hp_mean_p2_5\"] = p2_lastN_mean\n    f[\"late_game_hp_adv_5\"] = late_adv\n    f[\"late_game_domination_5\"] = 1.0 if late_adv > 0.0 else 0.0\n\n    # 4) Hazard pressure per turn (normalized)\n    # Requires that hazard flags and switch counts have been computed somewhere\n    # in the feature pipeline. If not yet, we'll default to zero.\n    haz_sw_diff = float(f.get(\"hazard_switch_pressure_diff\", 0.0))\n    turns_used = float(len(tl)) if tl else 1.0\n    f[\"hazard_pressure_per_turn\"] = haz_sw_diff / max(1.0, turns_used)\n\n    # --- New safe, bounded features (add near the end of _one_record_features) ---\n\n    # 1) Team offensive tilt: physical vs special (bounded, finite)\n    p1_sum_atk = float(sum(p.get(\"base_atk\", 0) for p in t1 if isinstance(p, dict)))\n    p1_sum_spa = float(sum(p.get(\"base_spa\", 0) for p in t1 if isinstance(p, dict)))\n    f[\"p1_offense_bias_ratio\"] = (p1_sum_atk + 1e-3) / (p1_sum_spa + 1e-3)  # >1 => more physical tilt\n    f[\"p1_offense_balance_gap\"] = p1_sum_atk - p1_sum_spa\n    \n    # 2) Defensive overlap: shared-weakness burden (small integers / means)\n    def _count_weaknesses_of_types(types):\n        prof = get_defensive_profile(types or [])\n        return float(sum(1 for m in prof.values() if m > 1.0))\n    \n    p1_weak_counts = []\n    for p in t1:\n        if isinstance(p, dict):\n            p1_weak_counts.append(_count_weaknesses_of_types(p.get(\"types\", [])))\n    \n    f[\"p1_weakness_mean\"] = float(np.mean(p1_weak_counts)) if p1_weak_counts else 0.0\n    f[\"p1_weakness_max\"]  = float(np.max(p1_weak_counts))  if p1_weak_counts else 0.0\n    \n    # 3) Breadth of resistances (unique resistances union)\n    def _unique_resistances(types):\n        prof = get_defensive_profile(types or [])\n        return {atk for atk, mult in prof.items() if 0.0 < mult < 1.0}\n    \n    res_sets = []\n    for p in t1:\n        if isinstance(p, dict):\n            res_sets.append(_unique_resistances(p.get(\"types\", [])))\n    union_res = set().union(*res_sets) if res_sets else set()\n    f[\"p1_unique_resistances\"] = float(len(union_res))\n    \n    # 4) Early HP volatility (first 5 turns), bounded by [0,100] deltas\n    def _safe_clip_hp(seq):\n        return [max(0.0, min(100.0, float(x))) for x in seq]\n    \n    def _mean_abs_step(arr):\n        return float(np.mean([abs(arr[i] - arr[i-1]) for i in range(1, len(arr))])) if len(arr) > 1 else 0.0\n    \n    p1_hp5 = _safe_clip_hp(_window(p1, 5))\n    p2_hp5 = _safe_clip_hp(_window(p2, 5))\n    f[\"p1_hp_abs_step_5\"] = _mean_abs_step(p1_hp5)\n    f[\"p2_hp_abs_step_5\"] = _mean_abs_step(p2_hp5)\n    f[\"hp_abs_step_gap_5\"] = f[\"p1_hp_abs_step_5\"] - f[\"p2_hp_abs_step_5\"]\n    \n    # 5) Hazards effectiveness given switches (difference version; robust via f.get)\n    haz_p1 = float(f.get(\"hazard_p1_flag\", 0.0))\n    haz_p2 = float(f.get(\"hazard_p2_flag\", 0.0))\n    sw_p1  = float(f.get(\"switch_p1_count\", 0.0))\n    sw_p2  = float(f.get(\"switch_p2_count\", 0.0))\n    haz_sw_p1 = haz_p1 * sw_p2\n    haz_sw_p2 = haz_p2 * sw_p1\n    f[\"hazard_switch_pressure_diff\"] = haz_sw_p1 - haz_sw_p2\n    \n    # 6) Late-game move accuracy advantage (last 5 turns), safe mean\n    def _avg_acc_lastN(timeline, who, n=5):\n        seq = timeline[-n:] if len(timeline) >= n else timeline\n        accs = []\n        for t in seq:\n            md = (t.get(f\"{who}_move_details\") or {})\n            a = md.get(\"accuracy\", None)\n            if isinstance(a, (int, float)):\n                accs.append(float(a))\n        return float(np.mean(accs)) if accs else 0.0\n    \n    f[\"late_acc_adv_5\"] = _avg_acc_lastN(tl, \"p1\", 5) - _avg_acc_lastN(tl, \"p2\", 5)\n\n    # --- Move-based features (full & 5 turns) ---\n    mv1_full = _move_stats_for_side(tl, \"p1\", None)\n    mv2_full = _move_stats_for_side(tl, \"p2\", None)\n    f.update(mv1_full); f.update(mv2_full)\n    f[\"mv_power_mean_ratio\"]  = _safe_ratio(mv1_full[\"mv_p1_power_mean\"], mv2_full[\"mv_p2_power_mean\"])\n    mv1_5 = _move_stats_for_side(tl, \"p1\", 5)\n    mv2_5 = _move_stats_for_side(tl, \"p2\", 5)\n    f.update(mv1_5); f.update(mv2_5)\n    \n    f[\"mv_power_mean_ratio_5\"] = _safe_ratio(mv1_5[\"mv_p1_power_mean_5\"], mv2_5[\"mv_p2_power_mean_5\"])\n    \n    # Matchup / switches / hazards / momentum / recovery / STAB / early / priority\n    f.update(_p1_vs_p2lead_matchup_index(r, tl))\n    f[\"switch_p1_count\"]=_switch_count(tl,\"p1\"); f[\"switch_p2_count\"]=_switch_count(tl,\"p2\")\n    f[\"switch_count_diff\"]=f[\"switch_p1_count\"]-f[\"switch_p2_count\"]\n    f.update(_hazard_flags(tl))\n    f.update(_recovery_pressure(tl))\n    f.update(_stab_features(r, max_turns=30))\n    f.update(_early_momentum_features(r, first_n=3))\n    f.update(_priority_feature_block(r))\n    f.update(new_features(r))\n    f.update(new_features_deb(r))\n    f.update(new_features_mirko(r))\n    # Extra strong engineered features (top-5)\n    f.update(extra_strong_features(r, tl, p1, p2, t1, lead))\n    # --- Top-5 extra engineered features (ratios & composite scores) ---\n    # 1) Final HP ratio: who ends higher, on a smooth scale\n    p1_last_hp = f.get(\"tl_p1_hp_last\", 0.0)\n    p2_last_hp = f.get(\"tl_p2_hp_last\", 0.0)\n    f[\"hp_final_ratio\"] = (p1_last_hp + 1.0) / (p2_last_hp + 1.0)\n\n    # 2) HP AUC ratio: sustained HP advantage over the whole battle\n    p1_auc = f.get(\"tl_p1_hp_auc\", 0.0)\n    p2_auc = f.get(\"tl_p2_hp_auc\", 0.0)\n    f[\"hp_auc_ratio\"] = (p1_auc + 1e-3) / (p2_auc + 1e-3)\n\n    # 3) Max speed ratio: fastest P1 vs P2 lead\n    p1_max_spe = f.get(\"p1_max_spe\", 0.0) if \"p1_max_spe\" in f else 0.0\n    p2_lead_spe = f.get(\"p2_lead_spe\", 0.0) if \"p2_lead_spe\" in f else 0.0\n    f[\"max_speed_ratio\"] = (p1_max_spe + 1.0) / (p2_lead_spe + 1.0)\n\n    # 4) Early momentum composite: early HP diff × priority advantage (first 5 turns)\n    early_hp_diff = f.get(\"early_hp_diff_mean_3\", 0.0)\n    prio_diff_5   = f.get(\"mv_priority_count_diff_5\", 0.0)\n    f[\"early_momentum_combo\"] = early_hp_diff * (1.0 + prio_diff_5)\n\n    # 5) Matchup × HP dominance: lead matchup index combined with HP diff\n    lead_match_full = f.get(\"lead_matchup_p1_index_full\", 0.0)\n    hp_diff_mean    = f.get(\"tl_hp_diff_mean\", 0.0)\n    # small scaling by 1/100 to keep the magnitude reasonable\n    f[\"matchup_hp_combo\"] = lead_match_full * (hp_diff_mean / 100.0)\n\n\n    # Team Winrate / HP resilience / Avg damage\n    try:\n        p1_team_names=_pnames_from_p1_team(r)\n        f[\"p1_team_winrate_score\"]=team_score_from_stats(p1_team_names, POKEMON_STATS, default_wr=0.5)\n    except Exception:\n        f[\"p1_team_winrate_score\"]=0.5\n    p1_names=_pnames_from_p1_team(r)\n    p2_name=_pname_from_p2_lead(r)\n    f[\"p1_team_avg_hp_score\"]=team_hp_score(p1_names, POKEMON_HP_STATS)\n    f[\"p2_lead_avg_hp\"]=POKEMON_HP_STATS.get(p2_name,{}).get(\"hp_mean\",50.0)\n    f[\"hp_resilience_diff\"]=f[\"p1_team_avg_hp_score\"] - f[\"p2_lead_avg_hp\"]\n    f[\"predicted_win_by_hp\"]=1.0 if f[\"hp_resilience_diff\"]>0 else 0.0\n\n    f.update(damage_feature_for_battle(r, pokemon_avg_damage))\n    \n    # Extra global strength features from POKEMON_STATS (if available)\n    try:\n        winrates = [\n            POKEMON_STATS.get((nm or \"\").strip().lower(), {}).get(\"winrate\", 0.5)\n            for nm in p1_team_names\n            if nm\n        ]\n        if winrates:\n            f[\"p1_team_max_winrate\"] = float(np.max(winrates))\n            f[\"p1_team_min_winrate\"] = float(np.min(winrates))\n            f[\"p1_team_winspread\"]   = f[\"p1_team_max_winrate\"] - f[\"p1_team_min_winrate\"]\n            f[\"p1_weaklink_gap\"]     = f[\"p1_team_winrate_score\"] - f[\"p1_team_min_winrate\"]\n        else:\n            f[\"p1_team_max_winrate\"] = 0.5\n            f[\"p1_team_min_winrate\"] = 0.5\n            f[\"p1_team_winspread\"]   = 0.0\n            f[\"p1_weaklink_gap\"]     = 0.0\n    except Exception:\n        f[\"p1_team_max_winrate\"] = 0.5\n        f[\"p1_team_min_winrate\"] = 0.5\n        f[\"p1_team_winspread\"]   = 0.0\n        f[\"p1_weaklink_gap\"]     = 0.0\n\n    # IDs / target\n    f[\"battle_id\"]=r.get(\"battle_id\")\n    if \"player_won\" in r:\n        f[\"player_won\"]= int(r[\"player_won\"]) if isinstance(r[\"player_won\"], bool) else r[\"player_won\"]\n    return f\n\n# ---------------------------------------------\n# Public API (same name & return type as starter)\n# ---------------------------------------------\ndef create_simple_features(data: list[dict]) -> pd.DataFrame:\n    rows=[]\n    for battle in tqdm(data, desc=\"Extracting features\"):\n        rows.append(_one_record_features(battle))\n    return pd.DataFrame(rows).fillna(0)\n\n# ---------------------------------------------\n# Run feature extraction\n# ---------------------------------------------\nprint(\"Processing training data...\")\ntrain_df = create_simple_features(train_data)\n\nprint(\"\\nProcessing test data...\")\ntest_data = []\nwith open(test_file_path, 'r', encoding='utf-8') as f:\n    for line in f:\n        test_data.append(json.loads(line))\ntest_df = create_simple_features(test_data)\n\nprint(\"\\nTraining features preview:\")\n\n# --- Manual interactions (robust to missing columns) ---\ndef _maybe_add_interactions(df: pd.DataFrame) -> pd.DataFrame:\n    def safe_mul(a, b, name):\n        if a in df.columns and b in df.columns:\n            df[name] = df[a] * df[b]\n\n    # Team strength × move power (full)\n    safe_mul(\"p1_team_stat_avg\", \"mv_p1_power_mean\", \"ix_p1avg_x_p1pow\")\n    # Speed × priority advantage (first 5 turns if available)\n    if \"spe_max_adv\" in df.columns and \"mv_priority_count_diff_5\" in df.columns:\n        df[\"ix_speed_x_prio5\"] = df[\"spe_max_adv\"] * df[\"mv_priority_count_diff_5\"]\n    # HP momentum × fraction of advantaged turns\n    safe_mul(\"tl_hp_diff_mean\", \"tl_frac_turns_advantage\", \"ix_hpmean_x_fracadv\")\n    # Early momentum × priority diff (first 5)\n    if \"early_hp_diff_mean_3\" in df.columns and \"mv_priority_count_diff_5\" in df.columns:\n        df[\"ix_early3_x_prio5\"] = df[\"early_hp_diff_mean_3\"] * df[\"mv_priority_count_diff_5\"]\n    # STAB advantage × early KO score\n    if \"stab_stab_ratio_diff_full\" in df.columns and \"early_first_ko_score_3\" in df.columns:\n        df[\"ix_stabdiff_x_firstko\"] = df[\"stab_stab_ratio_diff_full\"] * df[\"early_first_ko_score_3\"]\n    # Type effectiveness × STAB (full)\n    if \"ter_p1_vs_p2lead_full\" in df.columns and \"stab_stab_ratio_diff_full\" in df.columns:\n        df[\"ix_ter_x_stab_full\"] = df[\"ter_p1_vs_p2lead_full\"] * df[\"stab_stab_ratio_diff_full\"]\n    # Type effectiveness × early momentum (first 3)\n    if \"ter_p1_vs_p2lead_5\" in df.columns and \"early_hp_diff_mean_3\" in df.columns:\n        df[\"ix_ter5_x_early3\"] = df[\"ter_p1_vs_p2lead_5\"] * df[\"early_hp_diff_mean_3\"]\n    # Lead matchup × early momentum\n    if \"lead_matchup_p1_index_5\" in df.columns and \"early_hp_diff_mean_3\" in df.columns:\n        df[\"ix_leadmatch5_x_early3\"] = df[\"lead_matchup_p1_index_5\"] * df[\"early_hp_diff_mean_3\"]\n    # Hazards advantage × priority pressure\n    if \"hazard_flag_diff\" in df.columns and \"mv_priority_count_diff_5\" in df.columns:\n        df[\"ix_hazards_x_prio5\"] = df[\"hazard_flag_diff\"] * df[\"mv_priority_count_diff_5\"]\n    return df\n\ntrain_df = _maybe_add_interactions(train_df)\ntest_df  = _maybe_add_interactions(test_df)\n\n# === 2.x Custom predictive features (safe: no NaN, no div-by-zero) ===\n\nimport numpy as np\nimport pandas as pd\n\nEPS = 1e-6\nREPLACE_EXISTING = True  # set to False to skip creation if a feature name already exists\n\ndef _pick_first(df: pd.DataFrame, candidates, default_value=0.0):\n    \"\"\"Return the first existing column from candidates; else a float32 Series filled with default_value.\"\"\"\n    for c in candidates:\n        if c in df.columns:\n            return df[c].astype(\"float32\")\n    return pd.Series(default_value, index=df.index, dtype=\"float32\")\n\ndef _safe_div(a: pd.Series, b: pd.Series):\n    \"\"\"Elementwise safe division a/(b+EPS) with finite output.\"\"\"\n    out = a.astype(\"float32\") / (b.astype(\"float32\") + EPS)\n    out = out.replace([np.inf, -np.inf], 0.0).fillna(0.0).astype(\"float32\")\n    return out\n\ndef _ensure_float32(s: pd.Series):\n    return s.astype(\"float32\").replace([np.inf, -np.inf], 0.0).fillna(0.0)\n\ndef _normalize_acc(s: pd.Series):\n    \"\"\"If accuracy looks like [0..100], scale to [0..1].\"\"\"\n    s = _ensure_float32(s)\n    if len(s):\n        maxv = float(np.nanmax(s.values))\n    else:\n        maxv = 0.0\n    if maxv > 1.5:  # heuristically assume it's a percentage\n        s = s / 100.0\n    return s.clip(0.0, 1.0)\n\ndef _add_feature_pair(train_df, test_df, name, train_series, test_series):\n    \"\"\"Attach float32 features to both train and test with final sanitation.\"\"\"\n    if (not REPLACE_EXISTING) and (name in train_df.columns or name in test_df.columns):\n        return\n    train_df[name] = _ensure_float32(train_series)\n    test_df[name]  = _ensure_float32(test_series)\n\n# --- Robust base columns (try multiple candidates, fall back to zeros) ---\n\n# Attack / Defense (means)\natk_p1 = _pick_first(train_df, [\"atk_p1_mean\",\"atk_p1\",\"atk_p1_full\"], 0.0)\natk_p2 = _pick_first(train_df, [\"atk_p2_mean\",\"atk_p2\",\"atk_p2_full\"], 0.0)\ndef_p1 = _pick_first(train_df, [\"def_p1_mean\",\"def_p1\",\"def_p1_full\"], 0.0)\ndef_p2 = _pick_first(train_df, [\"def_p2_mean\",\"def_p2\",\"def_p2_full\"], 0.0)\n\natk_p1_te = _pick_first(test_df, [\"atk_p1_mean\",\"atk_p1\",\"atk_p1_full\"], 0.0)\natk_p2_te = _pick_first(test_df, [\"atk_p2_mean\",\"atk_p2\",\"atk_p2_full\"], 0.0)\ndef_p1_te = _pick_first(test_df, [\"def_p1_mean\",\"def_p1\",\"def_p1_full\"], 0.0)\ndef_p2_te = _pick_first(test_df, [\"def_p2_mean\",\"def_p2\",\"def_p2_full\"], 0.0)\n\n# Special Attack / Defense (means)\nsp_atk_p1 = _pick_first(train_df, [\"sp_atk_p1_mean\",\"spatk_p1_mean\",\"spa_p1_mean\",\"sp_atk_p1\"], 0.0)\nsp_atk_p2 = _pick_first(train_df, [\"sp_atk_p2_mean\",\"spatk_p2_mean\",\"spa_p2_mean\",\"sp_atk_p2\"], 0.0)\nsp_def_p1 = _pick_first(train_df, [\"sp_def_p1_mean\",\"spdef_p1_mean\",\"spd_p1_mean_def\",\"sp_def_p1\"], 0.0)\nsp_def_p2 = _pick_first(train_df, [\"sp_def_p2_mean\",\"spdef_p2_mean\",\"spd_p2_mean_def\",\"sp_def_p2\"], 0.0)\n\nsp_atk_p1_te = _pick_first(test_df, [\"sp_atk_p1_mean\",\"spatk_p1_mean\",\"spa_p1_mean\",\"sp_atk_p1\"], 0.0)\nsp_atk_p2_te = _pick_first(test_df, [\"sp_atk_p2_mean\",\"spatk_p2_mean\",\"spa_p2_mean\",\"sp_atk_p2\"], 0.0)\nsp_def_p1_te = _pick_first(test_df, [\"sp_def_p1_mean\",\"spdef_p1_mean\",\"spd_p1_mean_def\",\"sp_def_p1\"], 0.0)\nsp_def_p2_te = _pick_first(test_df, [\"sp_def_p2_mean\",\"spdef_p2_mean\",\"spd_p2_mean_def\",\"sp_def_p2\"], 0.0)\n\n# Speed (means)\nspd_p1 = _pick_first(train_df, [\"spd_p1_mean\",\"speed_p1_mean\",\"spd_p1\"], 0.0)\nspd_p2 = _pick_first(train_df, [\"spd_p2_mean\",\"speed_p2_mean\",\"spd_p2\"], 0.0)\nspd_p1_te = _pick_first(test_df,  [\"spd_p1_mean\",\"speed_p1_mean\",\"spd_p1\"], 0.0)\nspd_p2_te = _pick_first(test_df,  [\"spd_p2_mean\",\"speed_p2_mean\",\"spd_p2\"], 0.0)\n\n# HP current / max\nhp1_cur = _pick_first(train_df, [\"hp_p1_remain\",\"hp_p1_curr\",\"hp_p1\"], 0.0)\nhp2_cur = _pick_first(train_df, [\"hp_p2_remain\",\"hp_p2_curr\",\"hp_p2\"], 0.0)\nhp1_max = _pick_first(train_df, [\"hp_p1_max\",\"hp_p1_base\",\"hp_p1_total\"], 1.0)\nhp2_max = _pick_first(train_df, [\"hp_p2_max\",\"hp_p2_base\",\"hp_p2_total\"], 1.0)\n\nhp1_cur_te = _pick_first(test_df, [\"hp_p1_remain\",\"hp_p1_curr\",\"hp_p1\"], 0.0)\nhp2_cur_te = _pick_first(test_df, [\"hp_p2_remain\",\"hp_p2_curr\",\"hp_p2\"], 0.0)\nhp1_max_te = _pick_first(test_df, [\"hp_p1_max\",\"hp_p1_base\",\"hp_p1_total\"], 1.0)\nhp2_max_te = _pick_first(test_df, [\"hp_p2_max\",\"hp_p2_base\",\"hp_p2_total\"], 1.0)\n\n# Move power / accuracy\npwr_p1 = _pick_first(train_df, [\"mv_p1_power_mean_full\",\"mv_p1_power_mean\",\"mv_power_p1_mean\"], 0.0)\npwr_p2 = _pick_first(train_df, [\"mv_p2_power_mean_full\",\"mv_p2_power_mean\",\"mv_power_p2_mean\"], 0.0)\nacc_p1 = _normalize_acc(_pick_first(train_df, [\"mv_p1_acc_mean_full\",\"mv_p1_acc_mean\",\"mv_acc_p1_mean\"], 0.0))\nacc_p2 = _normalize_acc(_pick_first(train_df, [\"mv_p2_acc_mean_full\",\"mv_p2_acc_mean\",\"mv_acc_p2_mean\"], 0.0))\n\npwr_p1_te = _pick_first(test_df, [\"mv_p1_power_mean_full\",\"mv_p1_power_mean\",\"mv_power_p1_mean\"], 0.0)\npwr_p2_te = _pick_first(test_df, [\"mv_p2_power_mean_full\",\"mv_p2_power_mean\",\"mv_power_p2_mean\"], 0.0)\nacc_p1_te = _normalize_acc(_pick_first(test_df, [\"mv_p1_acc_mean_full\",\"mv_p1_acc_mean\",\"mv_acc_p1_mean\"], 0.0))\nacc_p2_te = _normalize_acc(_pick_first(test_df, [\"mv_p2_acc_mean_full\",\"mv_p2_acc_mean\",\"mv_acc_p2_mean\"], 0.0))\n\n# Move type counts (STATUS / PHYSICAL / SPECIAL) — safe fallbacks\nst_p1 = _pick_first(train_df, [\"mv_p1_count_STATUS_full\",\"mv_p1_count_STATUS\",\"status_moves_p1\"], 0.0)\nph_p1 = _pick_first(train_df, [\"mv_p1_count_PHYSICAL_full\",\"mv_p1_count_PHYSICAL\",\"physical_moves_p1\"], 0.0)\nsp_p1 = _pick_first(train_df, [\"mv_p1_count_SPECIAL_full\",\"mv_p1_count_SPECIAL\",\"special_moves_p1\"], 0.0)\nst_p2 = _pick_first(train_df, [\"mv_p2_count_STATUS_full\",\"mv_p2_count_STATUS\",\"status_moves_p2\"], 0.0)\nph_p2 = _pick_first(train_df, [\"mv_p2_count_PHYSICAL_full\",\"mv_p2_count_PHYSICAL\",\"physical_moves_p2\"], 0.0)\nsp_p2 = _pick_first(train_df, [\"mv_p2_count_SPECIAL_full\",\"mv_p2_count_SPECIAL\",\"special_moves_p2\"], 0.0)\n\nst_p1_te = _pick_first(test_df, [\"mv_p1_count_STATUS_full\",\"mv_p1_count_STATUS\",\"status_moves_p1\"], 0.0)\nph_p1_te = _pick_first(test_df, [\"mv_p1_count_PHYSICAL_full\",\"mv_p1_count_PHYSICAL\",\"physical_moves_p1\"], 0.0)\nsp_p1_te = _pick_first(test_df, [\"mv_p1_count_SPECIAL_full\",\"mv_p1_count_SPECIAL\",\"special_moves_p1\"], 0.0)\nst_p2_te = _pick_first(test_df, [\"mv_p2_count_STATUS_full\",\"mv_p2_count_STATUS\",\"status_moves_p2\"], 0.0)\nph_p2_te = _pick_first(test_df, [\"mv_p2_count_PHYSICAL_full\",\"mv_p2_count_PHYSICAL\",\"physical_moves_p2\"], 0.0)\nsp_p2_te = _pick_first(test_df, [\"mv_p2_count_SPECIAL_full\",\"mv_p2_count_SPECIAL\",\"special_moves_p2\"], 0.0)\n\n# ===============================\n# 10 SAFE, HIGH-SIGNAL FEATURES\n# ===============================\n\n# 1) atk_def_ratio: P1 attack vs P2 defense\n_add_feature_pair(\n    train_df, test_df, \"atk_def_ratio\",\n    _safe_div(atk_p1, def_p2),\n    _safe_div(atk_p1_te, def_p2_te)\n)\n\n# 2) spd_gap: P1 speed minus P2 speed\n_add_feature_pair(\n    train_df, test_df, \"spd_gap\",\n    (spd_p1 - spd_p2),\n    (spd_p1_te - spd_p2_te)\n)\n\n# 3) hp_ratio: P1 current HP vs P2 current HP\n_add_feature_pair(\n    train_df, test_df, \"hp_ratio\",\n    _safe_div(hp1_cur, hp2_cur),\n    _safe_div(hp1_cur_te, hp2_cur_te)\n)\n\n# 4) survival_score: (P1 HP%) - (P2 HP%)\n_add_feature_pair(\n    train_df, test_df, \"survival_score\",\n    _safe_div(hp1_cur, hp1_max) - _safe_div(hp2_cur, hp2_max),\n    _safe_div(hp1_cur_te, hp1_max_te) - _safe_div(hp2_cur_te, hp2_max_te)\n)\n\n# 5) momentum_index: (atk*spd)_P1 / (atk*spd)_P2\n_add_feature_pair(\n    train_df, test_df, \"momentum_index\",\n    _safe_div(atk_p1 * spd_p1, atk_p2 * spd_p2),\n    _safe_div(atk_p1_te * spd_p1_te, atk_p2_te * spd_p2_te)\n)\n\n# 6) power_acc_gap: (avg power weighted by acc) P1 - P2\npwa_p1 = _ensure_float32(pwr_p1 * acc_p1)\npwa_p2 = _ensure_float32(pwr_p2 * acc_p2)\npwa_p1_te = _ensure_float32(pwr_p1_te * acc_p1_te)\npwa_p2_te = _ensure_float32(pwr_p2_te * acc_p2_te)\n_add_feature_pair(\n    train_df, test_df, \"power_acc_gap\",\n    (pwa_p1 - pwa_p2),\n    (pwa_p1_te - pwa_p2_te)\n)\n\n# 7) offensive_balance: (atk + sp_atk) P1 / P2\n_add_feature_pair(\n    train_df, test_df, \"offensive_balance\",\n    _safe_div(atk_p1 + sp_atk_p1, atk_p2 + sp_atk_p2),\n    _safe_div(atk_p1_te + sp_atk_p1_te, atk_p2_te + sp_atk_p2_te)\n)\n\n# 8) defensive_efficiency: (def + sp_def) P1 / P2\n_add_feature_pair(\n    train_df, test_df, \"defensive_efficiency\",\n    _safe_div(def_p1 + sp_def_p1, def_p2 + sp_def_p2),\n    _safe_div(def_p1_te + sp_def_p1_te, def_p2_te + sp_def_p2_te)\n)\n\n# 9) status_influence: share STATUS moves P1 - P2\ntot_p1 = _ensure_float32(st_p1 + ph_p1 + sp_p1).replace(0.0, 1.0)\ntot_p2 = _ensure_float32(st_p2 + ph_p2 + sp_p2).replace(0.0, 1.0)\ntot_p1_te = _ensure_float32(st_p1_te + ph_p1_te + sp_p1_te).replace(0.0, 1.0)\ntot_p2_te = _ensure_float32(st_p2_te + ph_p2_te + sp_p2_te).replace(0.0, 1.0)\n\nstatus_share_p1 = _safe_div(st_p1, tot_p1)\nstatus_share_p2 = _safe_div(st_p2, tot_p2)\nstatus_share_p1_te = _safe_div(st_p1_te, tot_p1_te)\nstatus_share_p2_te = _safe_div(st_p2_te, tot_p2_te)\n\n_add_feature_pair(\n    train_df, test_df, \"status_influence\",\n    (status_share_p1 - status_share_p2),\n    (status_share_p1_te - status_share_p2_te)\n)\n\n# 10) speed_ratio: P1 speed / P2 speed\n_add_feature_pair(\n    train_df, test_df, \"speed_ratio\",\n    _safe_div(spd_p1, spd_p2),\n    _safe_div(spd_p1_te, spd_p2_te)\n)\n\n# --- Quick validation: no NaN/Inf and report how many were added ---\nnew_cols = [\n    \"atk_def_ratio\",\"spd_gap\",\"hp_ratio\",\"survival_score\",\"momentum_index\",\n    \"power_acc_gap\",\"offensive_balance\",\"defensive_efficiency\",\"status_influence\",\"speed_ratio\"\n]\nbad_train = train_df[new_cols].isna().sum().sum() + np.isinf(train_df[new_cols].to_numpy()).sum()\nbad_test  = test_df[new_cols].isna().sum().sum()  + np.isinf(test_df[new_cols].to_numpy()).sum()\nprint(f\"[FeatureEng] Added {len(new_cols)} engineered features. Bad values -> train: {bad_train}, test: {bad_test}\")\n\n# Keep a raw copy for inspection\ntrain_df_raw = train_df.copy()\ntest_df_raw = test_df.copy()\n\n# -------------------------------------------------\n# 17. SCALING (ROBUST SCALER)\n# -------------------------------------------------\n\n# Identify numeric columns (all except ID and target)\nnum_cols = [c for c in train_df.columns if c not in (\"battle_id\", \"player_won\")]\n\n# Fit the scaler on training numeric features only\nscaler = RobustScaler().fit(train_df[num_cols])\n\n# Apply transform\ntrain_df[num_cols] = scaler.transform(train_df[num_cols])\ntest_df[num_cols] = scaler.transform(test_df[num_cols])\n\nprint(\"\\nPreview (raw):\")\ndisplay(train_df_raw.head())\n\nprint(\"\\nScaling completed. Preview (scaled):\")\ndisplay(train_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T21:06:52.4974Z","iopub.execute_input":"2025-11-14T21:06:52.497691Z","iopub.status.idle":"2025-11-14T21:07:31.015302Z","shell.execute_reply.started":"2025-11-14T21:06:52.497674Z","shell.execute_reply":"2025-11-14T21:07:31.014056Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================\n# Cell 2B — Add 5 advanced meta-features\n# ============================\n# Assumes: train_df, test_df are already created in Cell 2.\n\nimport numpy as np\nimport pandas as pd\n\ndef _ensure_col(df: pd.DataFrame, col: str):\n    \"\"\"\n    If column 'col' is missing in df, create it filled with 0.0.\n    Returns the column as a Series (float32-compatible).\n    \"\"\"\n    if col not in df.columns:\n        df[col] = 0.0\n    return df[col]\n\ndef add_advanced_top5_features(df: pd.DataFrame, name: str = \"df\") -> pd.DataFrame:\n    \"\"\"\n    Add 5 highly predictive meta-features on top of existing ones.\n    All constructed from already computed features -> no NaN, no div by 0.\n    \"\"\"\n\n    # 1) Enhanced lead matchup score\n    #    Combines lead matchup index, type effectiveness and STAB edge in early turns.\n    lead_idx_5   = _ensure_col(df, \"lead_matchup_p1_index_5\")\n    ter_5        = _ensure_col(df, \"ter_p1_vs_p2lead_5\")\n    stab_diff_5  = _ensure_col(df, \"stab_stab_ratio_diff_w5\")\n    df[\"feat_lead_matchup_enh\"] = (\n        lead_idx_5 * ter_5 * (1.0 + stab_diff_5)\n    )\n\n    # 2) Team synergy score (winrate × resistances / weaknesses)\n    team_wr      = _ensure_col(df, \"p1_team_winrate_score\")\n    uniq_res     = _ensure_col(df, \"p1_unique_resistances\")\n    weak_mean    = _ensure_col(df, \"p1_weakness_mean\")\n    df[\"feat_team_synergy\"] = (\n        team_wr * (1.0 + uniq_res) / (1.0 + weak_mean)\n    )\n\n    # 3) Refined early momentum (HP diff × fraction of advantaged turns)\n    early_hp_diff = _ensure_col(df, \"early_hp_diff_mean_3\")\n    frac_adv      = _ensure_col(df, \"tl_frac_turns_advantage\")\n    df[\"feat_early_momentum_refined\"] = early_hp_diff * frac_adv\n\n    # 4) Kill pressure index (early power × relative power ratio)\n    mv_p1_pow5    = _ensure_col(df, \"mv_p1_power_mean_5\")\n    mv_pow_ratio5 = _ensure_col(df, \"mv_power_mean_ratio_5\")\n    df[\"feat_kill_pressure\"] = mv_p1_pow5 * mv_pow_ratio5\n\n    # 5) Switch disadvantage × damage trade → \"switch pressure score\"\n    switch_diff   = _ensure_col(df, \"switch_count_diff\")\n    dmg_ratio     = _ensure_col(df, \"damage_ratio\")\n    df[\"feat_switch_pressure\"] = switch_diff * dmg_ratio\n\n    # Clean up types & infinities for the new columns\n    new_cols = [\n        \"feat_lead_matchup_enh\",\n        \"feat_team_synergy\",\n        \"feat_early_momentum_refined\",\n        \"feat_kill_pressure\",\n        \"feat_switch_pressure\",\n    ]\n\n    for c in new_cols:\n        if c in df.columns:\n            s = pd.to_numeric(df[c], errors=\"coerce\").astype(\"float32\")\n            arr = s.to_numpy()\n            arr[~np.isfinite(arr)] = 0.0\n            df[c] = arr\n\n    print(f\"[Advanced Top-5] Added 5 features to {name}: {new_cols}\")\n    return df\n\ntrain_df = add_advanced_top5_features(train_df, name=\"train_df\")\ntest_df  = add_advanced_top5_features(test_df,  name=\"test_df\")\n# === Extra stack-oriented features (5 new columns) ===\n# Assumes these columns already exist in train_df / test_df:\n# final_hp_winner, tl_frac_turns_advantage,\n# final_status_advantage, damage_trade_ratio_weighted,\n# ko_advantage, tot_damage_diff,\n# p1_team_max_winrate, p1_team_min_winrate\n\nimport numpy as np\n\nfor df, name in [(train_df, \"train_df\"), (test_df, \"test_df\")]:\n\n    # 1) Clutch win: vince pur essendo stato spesso in svantaggio\n    df[\"clutch_win_index\"] = (\n        df[\"final_hp_winner\"].astype(float)\n        * (df[\"tl_frac_turns_advantage\"] < 0.4).astype(float)\n    ).astype(\"float32\")\n\n    # 2) Dominant win: vince ed è stato quasi sempre in vantaggio\n    df[\"dominant_win_index\"] = (\n        df[\"final_hp_winner\"].astype(float)\n        * (df[\"tl_frac_turns_advantage\"] > 0.7).astype(float)\n    ).astype(\"float32\")\n\n    # 3) Status efficiency: quanto bene converte lo status in vantaggio\n    df[\"status_efficiency\"] = (\n        df[\"final_status_advantage\"].astype(float)\n        * df[\"damage_trade_ratio_weighted\"].astype(float)\n    ).astype(\"float32\")\n\n    # 4) KO efficiency: KO advantage “normalizzato” per il danno totale\n    denom = 1.0 + df[\"tot_damage_diff\"].abs().astype(float)\n    df[\"ko_efficiency\"] = (\n        df[\"ko_advantage\"].astype(float) / denom\n    )\n    df[\"ko_efficiency\"].replace([np.inf, -np.inf], 0.0, inplace=True)\n    df[\"ko_efficiency\"] = df[\"ko_efficiency\"].fillna(0.0).astype(\"float32\")\n\n    # 5) Team winrate spread: quanto è disomogeneo il team (carry vs compagni)\n    df[\"team_winrate_spread\"] = (\n        df[\"p1_team_max_winrate\"].astype(float)\n        - df[\"p1_team_min_winrate\"].astype(float)\n    ).astype(\"float32\")\n\nprint(\"[Cell 2] Added 5 extra stack features:\",\n      [\"clutch_win_index\", \"dominant_win_index\",\n       \"status_efficiency\", \"ko_efficiency\", \"team_winrate_spread\"])\n\n# === Extra XGB-inspired features (added after base feature engineering) ===\nimport numpy as np\n\ndef _signed_log(series: pd.Series) -> pd.Series:\n    \"\"\"Signed log transform: sign(x) * log1p(|x|)\"\"\"\n    return np.sign(series) * np.log1p(np.abs(series))\n\nfor df in (train_df, test_df):\n    # 1) Signed log of total damage diff\n    if \"tot_damage_diff\" in df.columns:\n        df[\"signed_log_tot_damage_diff\"] = _signed_log(df[\"tot_damage_diff\"])\n    else:\n        df[\"signed_log_tot_damage_diff\"] = 0.0\n\n    # 2) Signed log of KO advantage\n    if \"ko_advantage\" in df.columns:\n        df[\"signed_log_ko_advantage\"] = _signed_log(df[\"ko_advantage\"])\n    else:\n        df[\"signed_log_ko_advantage\"] = 0.0\n\n    # 3) Damage x status advantage\n    if (\"damage_trade_ratio_weighted\" in df.columns) and (\"final_status_advantage\" in df.columns):\n        df[\"damage_x_status_adv\"] = df[\"damage_trade_ratio_weighted\"] * (1.0 + df[\"final_status_advantage\"])\n    else:\n        df[\"damage_x_status_adv\"] = 0.0\n\n    # 4) Damage x pre-battle team winrate\n    if (\"damage_trade_ratio_weighted\" in df.columns) and (\"p1_team_winrate_score\" in df.columns):\n        df[\"damage_x_team_winrate\"] = df[\"damage_trade_ratio_weighted\"] * df[\"p1_team_winrate_score\"]\n    else:\n        df[\"damage_x_team_winrate\"] = 0.0\n\n    # 5) Early pressure index (voluntary leaves first 3 turns + recover diff)\n    if (\"vol_leave_diff_3\" in df.columns) and (\"recover_count_diff\" in df.columns):\n        df[\"early_pressure_index\"] = df[\"vol_leave_diff_3\"] + 0.5 * df[\"recover_count_diff\"]\n    else:\n        df[\"early_pressure_index\"] = 0.0\n\nprint(\"\\n[Advanced Top-5] train_df shape:\", train_df.shape)\nprint(\"[Advanced Top-5] test_df  shape:\", test_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T21:07:41.178395Z","iopub.execute_input":"2025-11-14T21:07:41.179378Z","iopub.status.idle":"2025-11-14T21:07:41.236663Z","shell.execute_reply.started":"2025-11-14T21:07:41.179353Z","shell.execute_reply":"2025-11-14T21:07:41.235681Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Models Training","metadata":{"_uuid":"bf65b3bb-827a-47f0-8dd3-f95e03651f9b","_cell_guid":"08ffc5f5-2dcb-437a-9e3a-62dafe9e3e9e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 3.1 - Best Features Selection","metadata":{}},{"cell_type":"code","source":"# === 3.1 Feature pruning (A+B) + per-model Top-K selection (LR, XGB, RF) ===\n# - A: drop constant features  (GLOBAL: all models)\n# - B: correlation pruning (|ρ| > CORR_THRESHOLD) **ONLY for LR features**\n# - Then:\n#     * LR : top-K_LR by importance |coef|\n#     * XGB: top-K_XGB by feature_importances_\n#     * RF : top-K_RF  by feature_importances_\n# - Output:\n#     * selected_cols_lr, selected_cols_xgb, selected_cols_rf\n#     * train_reduced, test_reduced with the union of all selected columns\n#     * selected_cols (union) for compatibility with other cells\n\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\n\n# -----------------------\n# Config\n# -----------------------\nCORR_THRESHOLD = 0.95   # correlation pruning threshold (used ONLY for LR block)\n\nTOP_K_LR  = 90          # number of features for LR\nTOP_K_XGB = 187         # number of features for XGB\nTOP_K_RF  = 160         # number of features for RF\n\nassert \"train_df\" in globals() and \"test_df\" in globals(), \"Run Cell 2 before 3.1.\"\n\nTARGET_COL = \"player_won\"\nID_COLS = [c for c in [\"battle_id\", \"player_id\"] if c in train_df.columns]\n\nfeature_cols = [\n    c for c in train_df.columns\n    if c not in ID_COLS + [TARGET_COL]\n]\n\n# Base feature matrices (before pruning)\nX0 = train_df[feature_cols].copy()\nX0_test = test_df[feature_cols].copy()\ny = train_df[TARGET_COL].astype(int).values\n\nprint(f\"[Init] Starting with {X0.shape[1]} features.\")\n\n# -----------------------\n# (A) Constant-feature pruning (GLOBAL, for all models)\n# -----------------------\nconst_cols = [c for c in X0.columns if X0[c].nunique(dropna=True) <= 1]\n\nprint(f\"\\n[Pruning][A] Constant features removed (global): {len(const_cols)}\")\nif const_cols:\n    print(\"  -> Constant list (first 50):\", const_cols[:50])\n\nif const_cols:\n    X_base = X0.drop(columns=const_cols, errors=\"ignore\")\n    X_base_test = X0_test.drop(columns=const_cols, errors=\"ignore\")\nelse:\n    X_base = X0.copy()\n    X_base_test = X0_test.copy()\n\nprint(f\"[Pruning][A] After constant pruning: {X_base.shape[1]} features\")\n\n# Separate views for each model:\n# - X_LR  will undergo correlation pruning\n# - X_XGB and X_RF keep all remaining features (no correlation pruning)\nX_LR  = X_base.copy()\nX_XGB = X_base.copy()\nX_RF  = X_base.copy()\n\n# -----------------------\n# (B) Correlation pruning (|ρ| > CORR_THRESHOLD) ONLY for LR block\n# -----------------------\nprint(f\"\\n[Pruning][B] Correlation pruning for LR with |ρ| > {CORR_THRESHOLD} ...\")\n\nnum_X_lr = X_LR.select_dtypes(include=[np.number])\ncorr_matrix_lr = num_X_lr.corr().abs()\n\nupper_lr = corr_matrix_lr.where(\n    np.triu(np.ones(corr_matrix_lr.shape), k=1).astype(bool)\n)\n\nto_drop_corr_lr = [\n    col for col in upper_lr.columns\n    if any(upper_lr[col] > CORR_THRESHOLD)\n]\n\nprint(f\"[Pruning][B] LR correlation-dropped: {len(to_drop_corr_lr)}\")\nif to_drop_corr_lr:\n    print(\"  -> LR correlated list (first 50):\", to_drop_corr_lr[:50])\n    # IMPORTANT: we only drop them for X_LR (LR feature block)\n    X_LR.drop(columns=to_drop_corr_lr, inplace=True, errors=\"ignore\")\n\nprint(f\"[Pruning][B] After LR correlation pruning: {X_LR.shape[1]} LR features\")\n\n# -----------------------\n# Data preparation (simple imputation for LR & RF)\n# -----------------------\n# XGB natively handles NaN; for LR and RF we impute missing values with the median\nX_LR_imp = X_LR.fillna(X_LR.median(numeric_only=True))\nX_RF_imp = X_RF.fillna(X_RF.median(numeric_only=True))\n\n# XGB uses the non–correlation-pruned, non-imputed matrix\nX_XGB_imp = X_XGB\n\n# -----------------------\n# (1) XGBoost feature importance (on X_XGB_imp)\n# -----------------------\nprint(\"\\n[FS][XGB] Fitting XGBoost for feature importance...\")\n\nxgb_fs = xgb.XGBClassifier(\n    n_estimators=400,\n    learning_rate=0.05,\n    max_depth=5,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    reg_lambda=1.0,\n    reg_alpha=0.0,\n    objective=\"binary:logistic\",\n    eval_metric=\"logloss\",\n    random_state=11,\n    n_jobs=-1,\n    tree_method=\"hist\"\n)\nxgb_fs.fit(X_XGB_imp, y)\nxgb_imp_raw = xgb_fs.feature_importances_\nxgb_imp_dict = {col: imp for col, imp in zip(X_XGB.columns, xgb_imp_raw)}\n\n# -----------------------\n# (2) Random Forest feature importance (on X_RF_imp)\n# -----------------------\nprint(\"[FS][RF ] Fitting RandomForest for feature importance...\")\n\nrf_fs = RandomForestClassifier(\n    n_estimators=400,\n    max_depth=10,\n    min_samples_leaf=10,\n    max_features=\"sqrt\",\n    bootstrap=True,\n    n_jobs=-1,\n    random_state=99\n)\nrf_fs.fit(X_RF_imp, y)\nrf_imp_raw = rf_fs.feature_importances_\nrf_imp_dict = {col: imp for col, imp in zip(X_RF.columns, rf_imp_raw)}\n\n# -----------------------\n# (3) Logistic Regression feature importance (|coef|, on X_LR_imp)\n# -----------------------\nprint(\"[FS][LR ] Fitting LogisticRegression for feature importance...\")\n\nsca = StandardScaler()\nX_lr_std = sca.fit_transform(X_LR_imp)\n\nlr_fs = LogisticRegression(\n    solver=\"liblinear\",\n    penalty=\"l2\",\n    C=0.5,\n    max_iter=3000,\n    random_state=13\n)\nlr_fs.fit(X_lr_std, y)\nlr_imp_raw = np.abs(lr_fs.coef_[0])\n\nlr_imp_dict = {col: imp for col, imp in zip(X_LR.columns, lr_imp_raw)}\n\n# -----------------------\n# Build importance DataFrame over ALL non-constant features\n# (LR importance = 0 for features dropped by LR correlation pruning)\n# -----------------------\nall_cols_after_A = sorted(X_base.columns)\n\nlr_imp_all  = [lr_imp_dict.get(c, 0.0)  for c in all_cols_after_A]\nxgb_imp_all = [xgb_imp_dict.get(c, 0.0) for c in all_cols_after_A]\nrf_imp_all  = [rf_imp_dict.get(c, 0.0)  for c in all_cols_after_A]\n\nimp_df = pd.DataFrame({\n    \"feature\": all_cols_after_A,\n    \"lr_imp\":  lr_imp_all,\n    \"xgb_imp\": xgb_imp_all,\n    \"rf_imp\":  rf_imp_all,\n})\n\nimp_df = imp_df.fillna(0.0)\n\nprint(\"\\n[FS] Example top-10 by LR importance:\")\nprint(imp_df.sort_values(\"lr_imp\", ascending=False).head(10))\n\nprint(\"\\n[FS] Example top-10 by XGB importance:\")\nprint(imp_df.sort_values(\"xgb_imp\", ascending=False).head(10))\n\nprint(\"\\n[FS] Example top-10 by RF importance:\")\nprint(imp_df.sort_values(\"rf_imp\", ascending=False).head(10))\n\n# -----------------------\n# Top-K per model\n# -----------------------\ndef _top_k(feat_df, col_name, k):\n    k_eff = min(k, len(feat_df))\n    return feat_df.sort_values(col_name, ascending=False)[\"feature\"].head(k_eff).tolist()\n\nselected_cols_lr  = _top_k(imp_df, \"lr_imp\",  TOP_K_LR)\nselected_cols_xgb = _top_k(imp_df, \"xgb_imp\", TOP_K_XGB)\nselected_cols_rf  = _top_k(imp_df, \"rf_imp\",  TOP_K_RF)\n\nprint(f\"\\n[FS] Selected for LR  (TOP_K_LR={TOP_K_LR}): {len(selected_cols_lr)} features\")\nprint(\"     First 15 LR cols:\", selected_cols_lr[:15])\n\nprint(f\"\\n[FS] Selected for XGB (TOP_K_XGB={TOP_K_XGB}): {len(selected_cols_xgb)} features\")\nprint(\"     First 15 XGB cols:\", selected_cols_xgb[:15])\n\nprint(f\"\\n[FS] Selected for RF  (TOP_K_RF={TOP_K_RF}): {len(selected_cols_rf)} features\")\nprint(\"     First 15 RF cols:\", selected_cols_rf[:15])\n\n# Union of all columns used by at least one model\nall_cols_union = sorted(set(selected_cols_lr) | set(selected_cols_xgb) | set(selected_cols_rf))\n\nprint(f\"\\n[FS] Union of all selected cols (LR ∪ XGB ∪ RF): {len(all_cols_union)} features\")\n\n# -----------------------\n# Build reduced train/test frames\n# -----------------------\ntrain_reduced = pd.concat(\n    [train_df[ID_COLS + [TARGET_COL]], train_df[all_cols_union]],\n    axis=1\n)\ntest_reduced = pd.concat(\n    [test_df[ID_COLS], test_df[all_cols_union]],\n    axis=1\n)\n\n# For compatibility with existing code:\nselected_cols = all_cols_union\nselected_cols_union = all_cols_union\n\nprint(f\"[Output] train_reduced shape: {train_reduced.shape}\")\nprint(f\"[Output] test_reduced  shape: {test_reduced.shape}\")\nprint(f\"[Features] Union selected_cols ({len(selected_cols)}): first 25 -> {selected_cols[:25]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T21:04:27.570593Z","iopub.status.idle":"2025-11-14T21:04:27.570933Z","shell.execute_reply.started":"2025-11-14T21:04:27.570808Z","shell.execute_reply":"2025-11-14T21:04:27.570822Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.2 - Stacking (Logistic Regression + XGBoost-> Logistic Regression meta)","metadata":{"_uuid":"a5923783-e209-48a4-b3a5-b3b7a38c48ca","_cell_guid":"c9df0ffe-ef6c-43d3-925a-f0ccce90af01","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# === 3.2 Stacking (LogisticRegression + XGBoost + RandomForest -> LogisticRegression meta) ===\n# - Ogni base learner usa il proprio set di feature:\n#       * LR  -> selected_cols_lr  (standardizzato, no calibrazione)\n#       * XGB -> selected_cols_xgb (early stopping + calibrazione sigmoid)\n#       * RF  -> selected_cols_rf  (calibrazione sigmoid)\n# - True OOF stacking su 3 colonne [p_LR, p_XGB, p_RF]\n# - Meta-learner = LogisticRegression su queste 3 prob\n# - Espone: oof_meta_scores, meta_test_scores, y\n\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.calibration import CalibratedClassifierCV\nimport xgboost as xgb\n\nRANDOM_STATE= 42\nFOLDS = 20\nnp.random.seed(RANDOM_STATE)\n\n# --- Safety checks & matrici -----------------------------------------------\nassert \"train_reduced\" in globals() and \"test_reduced\" in globals(), \"Run 3.1 before 3.2.\"\nassert \"selected_cols_lr\"  in globals(), \"Missing 'selected_cols_lr' from 3.1.\"\nassert \"selected_cols_xgb\" in globals(), \"Missing 'selected_cols_xgb' from 3.1.\"\nassert \"selected_cols_rf\"  in globals(), \"Missing 'selected_cols_rf' from 3.1.\"\n\ny = train_reduced[\"player_won\"].astype(int).to_numpy()\n\nX_lr_full  = train_reduced[selected_cols_lr].to_numpy()\nX_xgb_full = train_reduced[selected_cols_xgb].to_numpy()\nX_rf_full  = train_reduced[selected_cols_rf].to_numpy()\n\nX_lr_test  = test_reduced[selected_cols_lr].to_numpy()\nX_xgb_test = test_reduced[selected_cols_xgb].to_numpy()\nX_rf_test  = test_reduced[selected_cols_rf].to_numpy()\n\nn_train = X_lr_full.shape[0]\nn_test  = X_lr_test.shape[0]\n\nprint(f\"[Stack LR+XGB+RF→LR] Using \"\n      f\"{len(selected_cols_lr)} LR features, \"\n      f\"{len(selected_cols_xgb)} XGB features, \"\n      f\"{len(selected_cols_rf)} RF features on {n_train} training rows.\")\n\n# --- Base learners config ---------------------------------------------------\n# LR\nbase_lr_seed = 13\n\n# XGB\nbase_xgb_params = dict(\n    n_estimators=2000,\n    learning_rate=0.03,\n    max_depth=6,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    reg_lambda=1.0,\n    reg_alpha=0.0,\n    objective=\"binary:logistic\",\n    eval_metric=\"logloss\",\n    random_state=11,\n    n_jobs=-1,\n    tree_method=\"hist\",\n    early_stopping_rounds=100\n)\n\n# RF\nbase_rf_seed = 99\nrf_base_params = dict(\n    n_estimators=400,\n    max_depth=8,\n    min_samples_leaf=20,\n    max_features=\"sqrt\",\n    bootstrap=True,\n    n_jobs=-1,\n    random_state=base_rf_seed\n)\n\n# --- OOF holders (3 base learners) ------------------------------------------\nn_base_for_meta = 3\noof_base = np.zeros((n_train, n_base_for_meta), dtype=float)\ntest_base_folds = np.zeros((n_test, n_base_for_meta, FOLDS), dtype=float)\n\nskf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\n\nprint(\"\\n[Per-fold validation summary]\")\nfor fold, (tr_idx, va_idx) in enumerate(skf.split(X_lr_full, y), 1):\n    X_lr_tr,  X_lr_va  = X_lr_full[tr_idx],  X_lr_full[va_idx]\n    X_xgb_tr, X_xgb_va = X_xgb_full[tr_idx], X_xgb_full[va_idx]\n    X_rf_tr,  X_rf_va  = X_rf_full[tr_idx],  X_rf_full[va_idx]\n    y_tr,     y_va     = y[tr_idx],         y[va_idx]\n\n    # ---- Base 1: Logistic Regression (scaled, no calibration) ----\n    lr_model = make_pipeline(\n        StandardScaler(),\n        LogisticRegression(\n            solver=\"liblinear\",\n            penalty=\"l2\",\n            C=0.5,\n            max_iter=3000,\n            random_state=base_lr_seed\n        )\n    )\n    lr_model.fit(X_lr_tr, y_tr)\n    lr_va = lr_model.predict_proba(X_lr_va)[:, 1]\n    lr_te = lr_model.predict_proba(X_lr_test)[:, 1]\n\n    # ---- Base 2: XGBoost (early stopping) + sigmoid calib on val ----\n    xgb_model = xgb.XGBClassifier(**base_xgb_params)\n    xgb_model.fit(\n        X_xgb_tr, y_tr,\n        eval_set=[(X_xgb_va, y_va)],\n        verbose=False\n    )\n\n    try:\n        best_it = getattr(xgb_model, \"best_iteration\", None)\n        if best_it is not None:\n            xgb_va_raw = xgb_model.predict_proba(\n                X_xgb_va, iteration_range=(0, best_it + 1)\n            )[:, 1]\n            xgb_te_raw = xgb_model.predict_proba(\n                X_xgb_test, iteration_range=(0, best_it + 1)\n            )[:, 1]\n        else:\n            xgb_va_raw = xgb_model.predict_proba(X_xgb_va)[:, 1]\n            xgb_te_raw = xgb_model.predict_proba(X_xgb_test)[:, 1]\n        used_best = best_it\n    except Exception:\n        xgb_va_raw = xgb_model.predict_proba(X_xgb_va)[:, 1]\n        xgb_te_raw = xgb_model.predict_proba(X_xgb_test)[:, 1]\n        used_best = \"N/A\"\n\n    xgb_cal = CalibratedClassifierCV(estimator=xgb_model, method=\"sigmoid\", cv=\"prefit\")\n    xgb_cal.fit(X_xgb_va, y_va)\n    xgb_va = xgb_cal.predict_proba(X_xgb_va)[:, 1]\n    xgb_te = xgb_cal.predict_proba(X_xgb_test)[:, 1]\n\n    # ---- Base 3: RandomForest + sigmoid calib on val ----\n    rf_model = RandomForestClassifier(**rf_base_params)\n    rf_model.fit(X_rf_tr, y_tr)\n    rf_cal = CalibratedClassifierCV(estimator=rf_model, method=\"sigmoid\", cv=\"prefit\")\n    rf_cal.fit(X_rf_va, y_va)\n    rf_va = rf_cal.predict_proba(X_rf_va)[:, 1]\n    rf_te = rf_cal.predict_proba(X_rf_test)[:, 1]\n\n    # ---- Store OOF & per-fold test probs (LR, XGB, RF) ----\n    oof_base[va_idx, 0] = lr_va\n    oof_base[va_idx, 1] = xgb_va\n    oof_base[va_idx, 2] = rf_va\n\n    test_base_folds[:, 0, fold - 1] = lr_te\n    test_base_folds[:, 1, fold - 1] = xgb_te\n    test_base_folds[:, 2, fold - 1] = rf_te\n\n    # ---- Fold metrics ----\n    def _rep(p):\n        acc = accuracy_score(y_va, (p >= 0.5).astype(int))\n        try:\n            auc = roc_auc_score(y_va, p)\n        except Exception:\n            auc = np.nan\n        return acc, auc\n\n    acc_lr,  auc_lr  = _rep(lr_va)\n    acc_xgb, auc_xgb = _rep(xgb_va)\n    acc_rf,  auc_rf  = _rep(rf_va)\n\n    print(f\"  [Fold {fold:2d}] \"\n          f\"LR   acc={acc_lr:.4f} | AUC={auc_lr:.4f}   ||  \"\n          f\"XGB  acc={acc_xgb:.4f} | AUC={auc_xgb:.4f} | best_iter={used_best}   ||  \"\n          f\"RF   acc={acc_rf:.4f}  | AUC={auc_rf:.4f}\")\n\n# --- Aggregate test probs per base learner ----------------------------------\ntest_base_mean = test_base_folds.mean(axis=2)   # shape: (n_test, 3)\n\n# --- Meta-learner su [p_LR, p_XGB, p_RF] -----------------------------------\nmeta_clf = LogisticRegression(\n    solver=\"lbfgs\",\n    penalty=\"l2\",\n    C=0.5,\n    max_iter=5000,\n    random_state=RANDOM_STATE\n)\n\noof_meta_scores = np.zeros(n_train, dtype=float)\nmeta_test_folds = np.zeros((n_test, FOLDS), dtype=float)\n\nskf_meta = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE + 1)\nfor fold, (tr_idx, va_idx) in enumerate(skf_meta.split(oof_base, y), 1):\n    X_tr_m, X_va_m = oof_base[tr_idx], oof_base[va_idx]\n    y_tr_m, y_va_m = y[tr_idx], y[va_idx]\n\n    meta_clf_fold = LogisticRegression(\n        solver=\"lbfgs\",\n        penalty=\"l2\",\n        C=1.0,\n        max_iter=5000,\n        random_state=RANDOM_STATE + fold\n    )\n    meta_clf_fold.fit(X_tr_m, y_tr_m)\n    oof_meta_scores[va_idx] = meta_clf_fold.predict_proba(X_va_m)[:, 1]\n    meta_test_folds[:, fold - 1] = meta_clf_fold.predict_proba(test_base_mean)[:, 1]\n\n# Fit finale del meta su tutto l'OOF\nmeta_clf.fit(oof_base, y)\nmeta_test_scores = meta_test_folds.mean(axis=1)\n\n# --- OOF report del meta predictor -----------------------------------------\noof_acc_default = accuracy_score(y, (oof_meta_scores >= 0.50).astype(int))\ntry:\n    oof_auc = roc_auc_score(y, oof_meta_scores)\nexcept Exception:\n    oof_auc = np.nan\n\nprint(\"\\n[OOF][Meta LR on LR+XGB+RF] Accuracy @ 0.50 = {:.4f}\".format(oof_acc_default))\nprint(\"[OOF][Meta LR on LR+XGB+RF] ROC-AUC         = {:.4f}\".format(oof_auc))\nprint(\"\\nReady for 3.3 threshold tuning (variables: oof_meta_scores, meta_test_scores, y)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T21:04:27.572621Z","iopub.status.idle":"2025-11-14T21:04:27.572961Z","shell.execute_reply.started":"2025-11-14T21:04:27.572831Z","shell.execute_reply":"2025-11-14T21:04:27.572843Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ====================================\n# 3.2-meta-extra — Meta-learner mini search (C & random_state)\n# ====================================\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, roc_auc_score\n\nassert \"oof_base\" in globals(), \"Need 'oof_base' from 3.2.\"\nassert \"y\" in globals(), \"Need 'y' labels.\"\nassert \"test_base_mean\" in globals(), \"Need 'test_base_mean' from 3.2.\"\n\nX_meta = np.asarray(oof_base, dtype=float)        # shape (n_train, n_base)\nX_meta_test = np.asarray(test_base_mean, dtype=float)  # shape (n_test, n_base)\ny_meta = np.asarray(y, dtype=int)\n\nMETA_RANDOM_STATES = [3, 5, 7, 11, 17]\nMETA_C_VALUES      = [0.5, 1.0, 1.5, 2.0]\n\nresults = []\nmeta_test_candidates = {}\nmeta_oof_candidates  = {}\n\nprint(\"[Meta-search] Exploring LogisticRegression(C, random_state) on meta level...\")\n\nfor rs in META_RANDOM_STATES:\n    for C in META_C_VALUES:\n        key = f\"rs{rs}_C{C}\"\n        clf = LogisticRegression(\n            solver=\"lbfgs\",\n            penalty=\"l2\",\n            C=C,\n            max_iter=5000,\n            random_state=rs,\n        )\n        clf.fit(X_meta, y_meta)\n        oof_pred = clf.predict_proba(X_meta)[:, 1]\n        try:\n            auc = roc_auc_score(y_meta, oof_pred)\n        except Exception:\n            auc = np.nan\n        acc = accuracy_score(y_meta, (oof_pred >= 0.5).astype(int))\n\n        results.append((key, acc, auc))\n        meta_test_candidates[key] = clf.predict_proba(X_meta_test)[:, 1]\n        meta_oof_candidates[key]  = oof_pred\n\n# Rank by AUC, then Accuracy\nresults_sorted = sorted(results, key=lambda x: (x[2], x[1]), reverse=True)\n\nprint(\"\\n[Meta-search] Top 5 configurations:\")\nfor r in results_sorted[:5]:\n    print(f\"  {r[0]} -> ACC={r[1]:.4f} | AUC={r[2]:.4f}\")\n\nbest_key, best_acc, best_auc = results_sorted[0]\nprint(f\"\\n[Meta-search] Selected best meta config: {best_key} (ACC={best_acc:.4f}, AUC={best_auc:.4f})\")\n\n# Override global meta scores with best configuration\noof_meta_scores = meta_oof_candidates[best_key]\nmeta_test_scores = meta_test_candidates[best_key]\n\nprint(\"\\n[Meta-search] Updated 'oof_meta_scores' and 'meta_test_scores' with best meta config.\")\nprint(\"You can now re-run 3.3 for threshold tuning using the improved meta predictions.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T21:04:27.573848Z","iopub.status.idle":"2025-11-14T21:04:27.574083Z","shell.execute_reply.started":"2025-11-14T21:04:27.573969Z","shell.execute_reply":"2025-11-14T21:04:27.573981Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.3 - Threshold tuning for the StackingClassifier (uses OOF probs)","metadata":{"_uuid":"bdd6313f-2062-42fa-b307-393d08e9a535","_cell_guid":"ff38c3fc-7871-4c84-a702-d12a57e52704","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# ====================================\n# 3.3 — Advanced Threshold Tuning\n# ====================================\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import (\n    accuracy_score,\n    f1_score,\n    matthews_corrcoef,\n    roc_auc_score,\n    log_loss,\n)\n\nassert \"oof_meta_scores\" in globals(), \"Run 3.2 first to get 'oof_meta_scores'.\"\nassert \"meta_test_scores\" in globals(), \"Run 3.2 first to get 'meta_test_scores'.\"\nassert \"y\" in globals(), \"Need training labels 'y'.\"\nassert \"test_df\" in globals(), \"Need 'test_df' with 'battle_id'.\"\n\noof_probs = np.asarray(oof_meta_scores, dtype=float)\ntest_probs = np.asarray(meta_test_scores, dtype=float)\ny_true = np.asarray(y, dtype=int)\n\nprint(f\"[3.3] Threshold tuning on {len(y_true)} OOF samples.\")\n\n# --- Scan thresholds ---\nthr_values = np.linspace(0.30, 0.70, 401)  # step ~0.001\nrows = []\n\nfor thr in thr_values:\n    pred = (oof_probs >= thr).astype(int)\n    acc = accuracy_score(y_true, pred)\n    f1  = f1_score(y_true, pred)\n    mcc = matthews_corrcoef(y_true, pred)\n    try:\n        auc = roc_auc_score(y_true, oof_probs)\n    except Exception:\n        auc = np.nan\n    ll  = log_loss(y_true, np.clip(oof_probs, 1e-6, 1-1e-6))\n    rows.append((thr, acc, f1, mcc, auc, ll))\n\nthr_df = pd.DataFrame(\n    rows,\n    columns=[\"threshold\", \"accuracy\", \"f1\", \"mcc\", \"auc\", \"logloss\"]\n)\n\n# --- Pick best thresholds according to different metrics ---\nbest_acc_row = thr_df.iloc[thr_df[\"accuracy\"].idxmax()]\nbest_f1_row  = thr_df.iloc[thr_df[\"f1\"].idxmax()]\nbest_mcc_row = thr_df.iloc[thr_df[\"mcc\"].idxmax()]\n\nprint(\"\\n[3.3] Best by Accuracy:\")\nprint(best_acc_row)\n\nprint(\"\\n[3.3] Best by F1:\")\nprint(best_f1_row)\n\nprint(\"\\n[3.3] Best by MCC:\")\nprint(best_mcc_row)\n\n# --- Main operating threshold: prefer Accuracy, break ties by F1 then MCC ---\nbest_row = best_acc_row.copy()\n\n# If F1-optimal threshold has same accuracy within 1e-4 but better F1, take that\nif abs(best_f1_row[\"accuracy\"] - best_row[\"accuracy\"]) < 1e-4 and best_f1_row[\"f1\"] > best_row[\"f1\"]:\n    best_row = best_f1_row\n\n# Similarly check MCC if still tied\nif abs(best_mcc_row[\"accuracy\"] - best_row[\"accuracy\"]) < 1e-4 and best_mcc_row[\"mcc\"] > best_row[\"mcc\"]:\n    best_row = best_mcc_row\n\nbest_threshold = float(best_row[\"threshold\"])\nprint(f\"\\n[3.3] Selected operating threshold = {best_threshold:.4f}\")\n\n# --- Final OOF report at selected threshold ---\nfinal_pred_oof = (oof_probs >= best_threshold).astype(int)\nfinal_acc = accuracy_score(y_true, final_pred_oof)\nfinal_f1  = f1_score(y_true, final_pred_oof)\nfinal_mcc = matthews_corrcoef(y_true, final_pred_oof)\ntry:\n    final_auc = roc_auc_score(y_true, oof_probs)\nexcept Exception:\n    final_auc = np.nan\n\nprint(\"\\n[3.3] Final OOF metrics at selected threshold:\")\nprint(f\"  Accuracy = {final_acc:.4f}\")\nprint(f\"  F1       = {final_f1:.4f}\")\nprint(f\"  MCC      = {final_mcc:.4f}\")\nprint(f\"  AUC      = {final_auc:.4f}\")\n\n# --- Build submission using selected threshold ---\ntest_pred_labels = (test_probs >= best_threshold).astype(int)\n\n# Alias for compatibility with Cell 4 (which expects 'stack_pred_labels_tuned')\nstack_pred_labels_tuned = test_pred_labels\n\nsubmission = pd.DataFrame({\n    \"battle_id\": test_df[\"battle_id\"].values,\n    \"player_won\": test_pred_labels,\n})\n\nprint(\"\\n[3.3] Submission preview:\")\ndisplay(submission.head())\n\n# Keep submission & best threshold for later\nstacking_best_threshold = best_threshold\nstacking_submission = submission.copy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T21:04:27.575032Z","iopub.status.idle":"2025-11-14T21:04:27.575266Z","shell.execute_reply.started":"2025-11-14T21:04:27.575158Z","shell.execute_reply":"2025-11-14T21:04:27.57517Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Creating the Submission File","metadata":{"_uuid":"fc400151-e3d6-481e-87dc-6e23ec10bb0b","_cell_guid":"fe1e5039-65ab-41a2-b17e-d0b74be840f8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# === 4. Build and save final submission ===\nimport numpy as np\nimport pandas as pd\n\n# --- Safety checks ---\nif \"meta_test_scores\" not in globals():\n    raise RuntimeError(\"Missing 'meta_test_scores'. Run Cells 3.2 and 3.3 first.\")\n\nif \"test_df\" not in globals() or \"battle_id\" not in test_df.columns:\n    raise RuntimeError(\"Missing 'test_df' with 'battle_id' column.\")\n\n# Prefer the name set in 3.3, otherwise fall back to best_threshold\nif \"stacking_best_threshold\" in globals():\n    thr = float(stacking_best_threshold)\nelif \"best_threshold\" in globals():\n    thr = float(best_threshold)\nelse:\n    raise RuntimeError(\"Missing best threshold. Run Cell 3.3 (advanced threshold tuning) first.\")\n\nprint(f\"[4] Using threshold = {thr:.4f} for final submission.\")\n\n# --- Convert test probabilities to labels ---\ntest_probs = np.asarray(meta_test_scores, dtype=float)\nstack_pred_labels_tuned = (test_probs >= thr).astype(int)\n\n# --- Build submission DataFrame ---\nsubmission = pd.DataFrame({\n    \"battle_id\": test_df[\"battle_id\"].values,\n    \"player_won\": stack_pred_labels_tuned,\n})\n\n# Save to CSV for Kaggle\nsubmission.to_csv(\"submission.csv\", index=False)\n\nprint(\"[4] Submission file 'submission.csv' created.\")\nprint(\"[4] Submission shape:\", submission.shape)\ndisplay(submission.head())\n\n# Keep handy in memory\nstacking_submission = submission.copy()\n\n","metadata":{"_uuid":"536ccc01-19ab-4d61-b21b-d403562a08dc","_cell_guid":"2a35849f-8198-4a64-9eb1-25bffb277291","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-14T21:04:27.575928Z","iopub.status.idle":"2025-11-14T21:04:27.576188Z","shell.execute_reply.started":"2025-11-14T21:04:27.57604Z","shell.execute_reply":"2025-11-14T21:04:27.576053Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5. Submitting Your Results\n\nOnce you have generated your `submission.csv` file, there are two primary ways to submit it to the competition.\n\n---\n\n#### Method A: Submitting Directly from the Notebook\n\nThis is the standard method for code competitions. It ensures that your submission is linked to the code that produced it, which is crucial for reproducibility.\n\n1.  **Save Your Work:** Click the **\"Save Version\"** button in the top-right corner of the notebook editor.\n2.  **Run the Notebook:** In the pop-up window, select **\"Save & Run All (Commit)\"** and then click the **\"Save\"** button. This will run your entire notebook from top to bottom and save the output, including your `submission.csv` file.\n3.  **Go to the Viewer:** Once the save process is complete, navigate to the notebook viewer page. \n4.  **Submit to Competition:** In the viewer, find the **\"Submit to Competition\"** section. This is usually located in the header of the output section or in the vertical \"...\" menu on the right side of the page. Clicking the **Submit** button this will submit your generated `submission.csv` file.\n\nAfter submitting, you will see your score in the **\"Submit to Competition\"** section or in the [Public Leaderboard](https://www.kaggle.com/competitions/fds-pokemon-battles-prediction-2025/leaderboard?).\n\n---\n\n#### Method B: Manual Upload\n\nYou can also generate your predictions and submission file using any environment you prefer (this notebook, Google Colab, or your local machine).\n\n1.  **Generate the `submission.csv` file** using your model.\n2.  **Download the file** to your computer.\n3.  **Navigate to the [Leaderboard Page](https://www.kaggle.com/competitions/fds-pokemon-battles-prediction-2025/leaderboard?)** and click on the **\"Submit Predictions\"** button.\n4.  **Upload Your File:** Drag and drop or select your `submission.csv` file to upload it.\n\nThis method is quick, but keep in mind that for the final evaluation, you might be required to provide the code that generated your submission.\n\nGood luck!","metadata":{"_uuid":"06a20782-709c-467d-b15a-c98f0653a2af","_cell_guid":"cd0077c1-c58f-4486-86d3-b2b38ecc0f55","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}}]}